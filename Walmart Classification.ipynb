{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: (Interactive Python) is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language, that offers introspection, rich media, shell syntax, tab completion, and history. IPython provides the following features:\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from sklearn import svm, tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inlineIPython (Interactive Python) is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language, that offers introspection, rich media, shell syntax, tab completion, and history. IPython provides the following features:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preview training data\n",
    "with ZipFile('train.csv.zip') as zf:\n",
    "    with zf.open('train.csv') as f:\n",
    "        train_data = pd.read_csv(f)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic DataFrame info\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values in original data\n",
    "print(train_data.isnull().sum(), '\\n')\n",
    "print(train_data.isnull().sum() / train_data.shape[0] * 100, \"\\n\")\n",
    "\n",
    "# Removing redundency in department description column\n",
    "print(train_data.DepartmentDescription.unique(), '\\n')\n",
    "train_data = train_data.replace('MENS WEAR', 'MENSWEAR')\n",
    "print(train_data.DepartmentDescription.unique(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit is an identifier variable, each value will be an observation in final dataset.\n",
    "train_data.drop_duplicates()\n",
    "\n",
    "# are upc and FinelineNumber always missing together?\n",
    "upc_null = train_data.Upc.isnull()\n",
    "print('% of UPC and FinelineNumber values missing together:', \n",
    "      train_data.FinelineNumber[upc_null].isnull().mean() * 100, '\\n')\n",
    "\n",
    "# what are the values of dept when upc/FinelineNumber are missing?\n",
    "print(\"Departments of missing items:\", \n",
    "      train_data.DepartmentDescription[upc_null].unique(), '\\n')\n",
    "\n",
    "# when dept is missing, are both upc and FinelineNumber missing?\n",
    "dept_null = train_data.DepartmentDescription.isnull()\n",
    "\n",
    "# only need to test one of upc and FinelineNumber\n",
    "print(\"% of upc/FinelineNumber values missing when dept is missing:\",\n",
    "      train_data.Upc[dept_null].isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA values\n",
    "train_data =  train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic DataFrame info after dropna()\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_data[['TripType', 'DepartmentDescription']]\n",
    "\n",
    "sample = pd.crosstab(index = train_data.TripType,\n",
    "                     columns = train_data.DepartmentDescription,\n",
    "                     rownames = ['TripType'],\n",
    "                     colnames = ['DepartmentDescription'],\n",
    "                     margins = False)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,18))\n",
    "sns.heatmap(ax = ax, data = sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Building\n",
    "def data_generator(data):\n",
    "    \n",
    "    data = train_data.copy()\n",
    "    dummies = pd.get_dummies(data.DepartmentDescription)\n",
    "    data[dummies.columns] = dummies\n",
    "    data_dummies = data.iloc[:, 7:]\n",
    "    data_dummies = data_dummies.apply(lambda n: n * data['ScanCount'])\n",
    "\n",
    "    data.loc[data.ScanCount < 0, 'Return'] = 1\n",
    "    data.loc[data.Return != 1, 'Return'] = 0\n",
    "    data = data[['TripType', 'VisitNumber', 'Weekday', 'ScanCount', 'Return']]\n",
    "    data = data.rename(columns = {\"ScanCount\": 'NumItems'})\n",
    "    data = pd.concat([data, data_dummies], axis = 1)\n",
    "\n",
    "    grouped = data.groupby(\"VisitNumber\")\n",
    "    grouped = grouped.agg({'Weekday': np.max, \"TripType\": np.max, \n",
    "                           'NumItems': np.sum, 'Return': np.max, \n",
    "                           '1-HR PHOTO': np.sum, 'ACCESSORIES': np.sum, \n",
    "                           'AUTOMOTIVE': np.sum, 'BAKERY': np.sum, \n",
    "                           'BATH AND SHOWER': np.sum, 'BEAUTY': np.sum, \n",
    "                           'BEDDING': np.sum, 'BOOKS AND MAGAZINES': np.sum, \n",
    "                           'BOYS WEAR': np.sum, 'BRAS & SHAPEWEAR': np.sum, \n",
    "                           'CAMERAS AND SUPPLIES': np.sum, 'CANDY, TOBACCO, COOKIES': np.sum, \n",
    "                           'CELEBRATION': np.sum, 'COMM BREAD': np.sum, \n",
    "                           'CONCEPT STORES': np.sum, 'COOK AND DINE': np.sum, \n",
    "                           'DAIRY': np.sum, 'DSD GROCERY': np.sum, \n",
    "                           'ELECTRONICS': np.sum, 'FABRICS AND CRAFTS': np.sum, \n",
    "                           'FINANCIAL SERVICES': np.sum, 'FROZEN FOODS': np.sum, \n",
    "                           'FURNITURE': np.sum, 'GIRLS WEAR, 4-6X  AND 7-14': np.sum, \n",
    "                           'GROCERY DRY GOODS': np.sum, 'HARDWARE': np.sum, \n",
    "                           'HEALTH AND BEAUTY AIDS': np.sum, 'HOME DECOR': np.sum, \n",
    "                           'HOME MANAGEMENT': np.sum, 'HORTICULTURE AND ACCESS': np.sum, \n",
    "                           'HOUSEHOLD CHEMICALS/SUPP': np.sum,\n",
    "                           'HOUSEHOLD PAPER GOODS': np.sum, 'IMPULSE MERCHANDISE': np.sum, \n",
    "                           'INFANT APPAREL': np.sum, 'INFANT CONSUMABLE HARDLINES': np.sum,\n",
    "                           'JEWELRY AND SUNGLASSES': np.sum, 'LADIES SOCKS': np.sum, \n",
    "                           'LADIESWEAR': np.sum, 'LARGE HOUSEHOLD GOODS': np.sum, \n",
    "                           'LAWN AND GARDEN': np.sum, 'LIQUOR,WINE,BEER': np.sum, \n",
    "                           'MEAT - FRESH & FROZEN': np.sum, 'MEDIA AND GAMING': np.sum,\n",
    "                           'MENSWEAR': np.sum, 'OFFICE SUPPLIES': np.sum, \n",
    "                           'OPTICAL - FRAMES': np.sum, 'OPTICAL - LENSES': np.sum,\n",
    "                           'OTHER DEPARTMENTS': np.sum, 'PAINT AND ACCESSORIES': np.sum, \n",
    "                           'PERSONAL CARE': np.sum, 'PETS AND SUPPLIES': np.sum, \n",
    "                           'PHARMACY OTC': np.sum, 'PHARMACY RX': np.sum, \n",
    "                           'PLAYERS AND ELECTRONICS': np.sum, 'PLUS AND MATERNITY': np.sum, \n",
    "                           'PRE PACKED DELI': np.sum, 'PRODUCE': np.sum, \n",
    "                           'SEAFOOD': np.sum, 'SEASONAL': np.sum, \n",
    "                           'SERVICE DELI': np.sum, 'SHEER HOSIERY': np.sum, \n",
    "                           'SHOES': np.sum, 'SLEEPWEAR/FOUNDATIONS': np.sum, \n",
    "                           'SPORTING GOODS': np.sum, 'SWIMWEAR/OUTERWEAR': np.sum, \n",
    "                           'TOYS': np.sum, 'WIRELESS': np.sum})\n",
    "    \n",
    "    data = grouped[[\"TripType\", \"Weekday\", \"NumItems\", \"Return\",'1-HR PHOTO', \n",
    "                    'ACCESSORIES', 'AUTOMOTIVE', 'BAKERY', 'BATH AND SHOWER', 'BEAUTY', 'BEDDING', \n",
    "                    'BOOKS AND MAGAZINES', 'BOYS WEAR', 'BRAS & SHAPEWEAR', 'CAMERAS AND SUPPLIES', \n",
    "                    'CANDY, TOBACCO, COOKIES', 'CELEBRATION', 'COMM BREAD', 'CONCEPT STORES', \n",
    "                    'COOK AND DINE', 'DAIRY', 'DSD GROCERY', 'ELECTRONICS', 'FABRICS AND CRAFTS', \n",
    "                    'FINANCIAL SERVICES', 'FROZEN FOODS', 'FURNITURE', 'GIRLS WEAR, 4-6X  AND 7-14', \n",
    "                    'GROCERY DRY GOODS', 'HARDWARE', 'HEALTH AND BEAUTY AIDS', 'HOME DECOR', \n",
    "                    'HOME MANAGEMENT', 'HORTICULTURE AND ACCESS','HOUSEHOLD CHEMICALS/SUPP', \n",
    "                    'HOUSEHOLD PAPER GOODS', 'IMPULSE MERCHANDISE', 'INFANT APPAREL', \n",
    "                    'INFANT CONSUMABLE HARDLINES','JEWELRY AND SUNGLASSES', 'LADIES SOCKS', \n",
    "                    'LADIESWEAR', 'LARGE HOUSEHOLD GOODS', 'LAWN AND GARDEN', 'LIQUOR,WINE,BEER', \n",
    "                    'MEAT - FRESH & FROZEN', 'MEDIA AND GAMING', 'MENSWEAR', 'OFFICE SUPPLIES', \n",
    "                    'OPTICAL - FRAMES', 'OPTICAL - LENSES', 'OTHER DEPARTMENTS', 'PAINT AND ACCESSORIES', \n",
    "                    'PERSONAL CARE','PETS AND SUPPLIES', 'PHARMACY OTC', 'PHARMACY RX', \n",
    "                    'PLAYERS AND ELECTRONICS', 'PLUS AND MATERNITY','PRE PACKED DELI', 'PRODUCE', \n",
    "                    'SEAFOOD', 'SEASONAL', 'SERVICE DELI', 'SHEER HOSIERY', 'SHOES', \n",
    "                    'SLEEPWEAR/FOUNDATIONS', 'SPORTING GOODS', 'SWIMWEAR/OUTERWEAR','TOYS', 'WIRELESS']]\n",
    "#     data.head()\n",
    "    return data\n",
    "\n",
    "train_data = data_generator(train_data)\n",
    "print(train_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19ee69f3df0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting the bar chart for the trip types \n",
    "plt.figure(figsize = (12, 8))\n",
    "train_data['TripType'].value_counts().plot(kind = 'bar', title = 'Trip Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant class imbalance in terms of predicting object, TripType. So eliminating extremely popular trip types and unpopular trip types to balance classes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>NumItems</th>\n",
       "      <th>Return</th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEDDING</th>\n",
       "      <th>...</th>\n",
       "      <th>SEAFOOD</th>\n",
       "      <th>SEASONAL</th>\n",
       "      <th>SERVICE DELI</th>\n",
       "      <th>SHEER HOSIERY</th>\n",
       "      <th>SHOES</th>\n",
       "      <th>SLEEPWEAR/FOUNDATIONS</th>\n",
       "      <th>SPORTING GOODS</th>\n",
       "      <th>SWIMWEAR/OUTERWEAR</th>\n",
       "      <th>TOYS</th>\n",
       "      <th>WIRELESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "      <td>26035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.557519</td>\n",
       "      <td>7.899674</td>\n",
       "      <td>0.052468</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.076743</td>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.234722</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.064721</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.045016</td>\n",
       "      <td>0.043211</td>\n",
       "      <td>0.017976</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.028308</td>\n",
       "      <td>0.002458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.385487</td>\n",
       "      <td>8.460352</td>\n",
       "      <td>0.222973</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.142963</td>\n",
       "      <td>0.209009</td>\n",
       "      <td>0.393476</td>\n",
       "      <td>0.798115</td>\n",
       "      <td>1.035118</td>\n",
       "      <td>0.461824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176234</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.352884</td>\n",
       "      <td>0.134264</td>\n",
       "      <td>0.305593</td>\n",
       "      <td>0.375683</td>\n",
       "      <td>0.195359</td>\n",
       "      <td>0.194148</td>\n",
       "      <td>0.249924</td>\n",
       "      <td>0.058745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TripType      NumItems        Return    1-HR PHOTO   ACCESSORIES  \\\n",
       "count  26035.000000  26035.000000  26035.000000  26035.000000  26035.000000   \n",
       "mean      24.557519      7.899674      0.052468      0.001306      0.010563   \n",
       "std       13.385487      8.460352      0.222973      0.066160      0.142963   \n",
       "min        3.000000     -2.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.000000      3.000000      0.000000      0.000000      0.000000   \n",
       "50%       25.000000      5.000000      0.000000      0.000000      0.000000   \n",
       "75%       36.000000     10.000000      0.000000      0.000000      0.000000   \n",
       "max       38.000000    311.000000      1.000000      7.000000      7.000000   \n",
       "\n",
       "         AUTOMOTIVE        BAKERY  BATH AND SHOWER        BEAUTY  \\\n",
       "count  26035.000000  26035.000000     26035.000000  26035.000000   \n",
       "mean       0.020280      0.076743         0.085577      0.234722   \n",
       "std        0.209009      0.393476         0.798115      1.035118   \n",
       "min        0.000000      0.000000         0.000000      0.000000   \n",
       "25%        0.000000      0.000000         0.000000      0.000000   \n",
       "50%        0.000000      0.000000         0.000000      0.000000   \n",
       "75%        0.000000      0.000000         0.000000      0.000000   \n",
       "max       10.000000     12.000000        67.000000     45.000000   \n",
       "\n",
       "            BEDDING  ...       SEAFOOD      SEASONAL  SERVICE DELI  \\\n",
       "count  26035.000000  ...  26035.000000  26035.000000  26035.000000   \n",
       "mean       0.054888  ...      0.015710      0.000192      0.064721   \n",
       "std        0.461824  ...      0.176234      0.016396      0.352884   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "max       18.000000  ...      7.000000      2.000000      8.000000   \n",
       "\n",
       "       SHEER HOSIERY         SHOES  SLEEPWEAR/FOUNDATIONS  SPORTING GOODS  \\\n",
       "count   26035.000000  26035.000000           26035.000000    26035.000000   \n",
       "mean        0.005147      0.045016               0.043211        0.017976   \n",
       "std         0.134264      0.305593               0.375683        0.195359   \n",
       "min         0.000000      0.000000               0.000000        0.000000   \n",
       "25%         0.000000      0.000000               0.000000        0.000000   \n",
       "50%         0.000000      0.000000               0.000000        0.000000   \n",
       "75%         0.000000      0.000000               0.000000        0.000000   \n",
       "max        10.000000     12.000000              18.000000       12.000000   \n",
       "\n",
       "       SWIMWEAR/OUTERWEAR          TOYS      WIRELESS  \n",
       "count        26035.000000  26035.000000  26035.000000  \n",
       "mean             0.014788      0.028308      0.002458  \n",
       "std              0.194148      0.249924      0.058745  \n",
       "min              0.000000      0.000000      0.000000  \n",
       "25%              0.000000      0.000000      0.000000  \n",
       "50%              0.000000      0.000000      0.000000  \n",
       "75%              0.000000      0.000000      0.000000  \n",
       "max              8.000000     10.000000      4.000000  \n",
       "\n",
       "[8 rows x 70 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show data descriptions\n",
    "train_data = train_data[train_data.TripType.isin([25, 3, 5, 36, 38, 37, 24, 35, 32])]\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEALTH AND BEAUTY AIDS     0.000038\n",
       "CONCEPT STORES             0.000077\n",
       "OTHER DEPARTMENTS          0.000115\n",
       "SEASONAL                   0.000192\n",
       "CAMERAS AND SUPPLIES       0.000576\n",
       "1-HR PHOTO                 0.001306\n",
       "PLAYERS AND ELECTRONICS    0.001767\n",
       "WIRELESS                   0.002458\n",
       "LARGE HOUSEHOLD GOODS      0.002919\n",
       "OPTICAL - LENSES           0.003342\n",
       "SHEER HOSIERY              0.005147\n",
       "BOOKS AND MAGAZINES        0.006683\n",
       "MEDIA AND GAMING           0.006722\n",
       "PHARMACY RX                0.006799\n",
       "ELECTRONICS                0.007413\n",
       "PAINT AND ACCESSORIES      0.008258\n",
       "ACCESSORIES                0.010563\n",
       "HORTICULTURE AND ACCESS    0.010716\n",
       "LADIES SOCKS               0.011792\n",
       "PLUS AND MATERNITY         0.012022\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the mean of bottom 20 departments\n",
    "train_data.mean().sort_values().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19e802f27f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting the bar chart for the trip types \n",
    "plt.figure(figsize=(12,8))\n",
    "train_data['TripType'].value_counts().plot(kind = 'bar', title = 'Trip Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting histogram for daywise visits\n",
    "plt.figure(figsize=(12,8))\n",
    "num_bins = 7\n",
    "n, bins, patches = plt.hist(train_data['Weekday'], num_bins, alpha = 0.5)\n",
    "plt.xlabel('Weekdays')\n",
    "plt.ylabel('Number of Purchased')\n",
    "plt.title(\"Daywise Visits in a Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>NumItems</th>\n",
       "      <th>Return</th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>...</th>\n",
       "      <th>SEAFOOD</th>\n",
       "      <th>SEASONAL</th>\n",
       "      <th>SERVICE DELI</th>\n",
       "      <th>SHEER HOSIERY</th>\n",
       "      <th>SHOES</th>\n",
       "      <th>SLEEPWEAR/FOUNDATIONS</th>\n",
       "      <th>SPORTING GOODS</th>\n",
       "      <th>SWIMWEAR/OUTERWEAR</th>\n",
       "      <th>TOYS</th>\n",
       "      <th>WIRELESS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisitNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191326</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191329</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191335</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191337</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191343</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26035 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TripType  Weekday  NumItems  Return  1-HR PHOTO  ACCESSORIES  \\\n",
       "VisitNumber                                                                 \n",
       "11                 35        0         4     0.0           0            0   \n",
       "28                 25        0         8     0.0           0            0   \n",
       "43                 38        0         4     0.0           0            0   \n",
       "47                 35        0         5     0.0           0            0   \n",
       "63                 36        0         5     0.0           0            0   \n",
       "...               ...      ...       ...     ...         ...          ...   \n",
       "191326             38        3        11     0.0           0            0   \n",
       "191329             24        3        20     0.0           0            0   \n",
       "191335             32        3         9     0.0           0            0   \n",
       "191337             38        3        27     1.0           0            0   \n",
       "191343             25        3         9     0.0           0            0   \n",
       "\n",
       "             AUTOMOTIVE  BAKERY  BATH AND SHOWER  BEAUTY  ...  SEAFOOD  \\\n",
       "VisitNumber                                               ...            \n",
       "11                    0       0                0       0  ...        0   \n",
       "28                    0       2                0       0  ...        0   \n",
       "43                    0       0                0       0  ...        0   \n",
       "47                    0       0                0       0  ...        0   \n",
       "63                    0       0                0       1  ...        0   \n",
       "...                 ...     ...              ...     ...  ...      ...   \n",
       "191326                0       0                0       0  ...        0   \n",
       "191329                0       0                2       0  ...        0   \n",
       "191335                0       0                0       0  ...        0   \n",
       "191337                0       1                0       0  ...        0   \n",
       "191343                0       0                0       0  ...        0   \n",
       "\n",
       "             SEASONAL  SERVICE DELI  SHEER HOSIERY  SHOES  \\\n",
       "VisitNumber                                                 \n",
       "11                  0             0              0      0   \n",
       "28                  0             0              0      0   \n",
       "43                  0             0              0      0   \n",
       "47                  0             0              0      0   \n",
       "63                  0             0              0      0   \n",
       "...               ...           ...            ...    ...   \n",
       "191326              0             0              0      0   \n",
       "191329              0             0              0      0   \n",
       "191335              0             0              0      0   \n",
       "191337              0             0              0      0   \n",
       "191343              0             0              0      0   \n",
       "\n",
       "             SLEEPWEAR/FOUNDATIONS  SPORTING GOODS  SWIMWEAR/OUTERWEAR  TOYS  \\\n",
       "VisitNumber                                                                    \n",
       "11                               0               0                   0     0   \n",
       "28                               0               0                   0     0   \n",
       "43                               0               0                   0     0   \n",
       "47                               0               0                   0     0   \n",
       "63                               0               0                   0     0   \n",
       "...                            ...             ...                 ...   ...   \n",
       "191326                           0               0                   0     0   \n",
       "191329                           0               0                   0     0   \n",
       "191335                           0               0                   0     0   \n",
       "191337                           0               0                   0     0   \n",
       "191343                           0               0                   0     0   \n",
       "\n",
       "             WIRELESS  \n",
       "VisitNumber            \n",
       "11                  0  \n",
       "28                  0  \n",
       "43                  0  \n",
       "47                  0  \n",
       "63                  0  \n",
       "...               ...  \n",
       "191326              0  \n",
       "191329              0  \n",
       "191335              0  \n",
       "191337              0  \n",
       "191343              0  \n",
       "\n",
       "[26035 rows x 71 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply label encoder to transform categorical data Weekday\n",
    "label_encoder = LabelEncoder()\n",
    "train_data.Weekday = label_encoder.fit_transform(np.array(train_data.Weekday))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test & Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data preprocesssing dropping na and splitting data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['TripType',\n",
    "                                                                     'HEALTH AND BEAUTY AIDS',\n",
    "                                                                     'CONCEPT STORES',\n",
    "                                                                     'OTHER DEPARTMENTS',\n",
    "                                                                     'SEASONAL',\n",
    "                                                                     'CAMERAS AND SUPPLIES',\n",
    "                                                                     '1-HR PHOTO'], \n",
    "                                                                    axis = 'columns').values,\n",
    "                                                    train_data.TripType.values,\n",
    "                                                    train_size = 0.8,\n",
    "                                                    random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20828, 64) \n",
      "\n",
      "(5207, 64) \n",
      "\n",
      "(20828,) \n",
      "\n",
      "(5207,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show data shape\n",
    "print(X_train.shape, '\\n')\n",
    "print(X_test.shape, '\\n')\n",
    "print(y_train.shape, '\\n')\n",
    "print(y_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show data with cleaned features\n",
    "features_cleaned = train_data.drop(['TripType',\n",
    "                                    'HEALTH AND BEAUTY AIDS',\n",
    "                                    'CONCEPT STORES',\n",
    "                                    'OTHER DEPARTMENTS',\n",
    "                                    'SEASONAL',\n",
    "                                    'CAMERAS AND SUPPLIES',\n",
    "                                    '1-HR PHOTO'], \n",
    "                                   axis = 'columns').columns.values\n",
    "len(features_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 1, penalty = 'l2', tol = 1e-4, solver = 'saga')\n",
    "lr = lr.fit(X_train, y_train)\n",
    "lr_predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression prediction is 87.08%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Logistic Regression prediction is\", '{:.2%}'.format(accuracy_score(y_test, lr_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_cleaned</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumItems</td>\n",
       "      <td>-0.42012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PHARMACY OTC</td>\n",
       "      <td>-0.327489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>-0.291853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>-0.225593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>-0.215353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>0.00452376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LARGE HOUSEHOLD GOODS</td>\n",
       "      <td>0.0934588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekday</td>\n",
       "      <td>0.173167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>0.320258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>2.19111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         features_cleaned importance_score\n",
       "1                NumItems         -0.42012\n",
       "49           PHARMACY OTC        -0.327489\n",
       "17            DSD GROCERY        -0.291853\n",
       "47          PERSONAL CARE        -0.225593\n",
       "54                PRODUCE        -0.215353\n",
       "..                    ...              ...\n",
       "18            ELECTRONICS       0.00452376\n",
       "37  LARGE HOUSEHOLD GOODS        0.0934588\n",
       "0                 Weekday         0.173167\n",
       "31    IMPULSE MERCHANDISE         0.320258\n",
       "20     FINANCIAL SERVICES          2.19111\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = lr.coef_[0]\n",
    "importance_score = []\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    importance_score.append(v)\n",
    "    \n",
    "importance_table = pd.DataFrame([features_cleaned, importance_score]).T\n",
    "importance_table.columns = ['features_cleaned', 'importance_score']\n",
    "importance_table = importance_table.sort_values('importance_score')\n",
    "importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Logistic Regression prediction is 0.56\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Logistic Regression prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, lr.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>598</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>384</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>323</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>527</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>479</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          711    1    0    1    0   14    1    2    0\n",
       "5            1  598    7    3    1    5   22    7    9\n",
       "24          13   17  384   15    1   11   19   13   12\n",
       "25           3   16    2  691    4   10   18   12    9\n",
       "32           5    2    5   10  323   14   14    1   14\n",
       "35           0    7    6    3    1  320    5   15   36\n",
       "36           5   40   10   13    4    5  527    7    9\n",
       "37           2    8   11    1    2   13    4  479   37\n",
       "38           4    9   12    5    3   35   16   31  501"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = lr_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.89       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.81      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0000\n",
      "Sparsity with L1 penalty:                3.12%\n",
      "Sparsity with L2 penalty:                0.00%\n",
      "Sparsity with Elastic-Net penalty:       0.69%\n",
      "Score with L1 penalty:                   0.87\n",
      "Score with L2 penalty:                   0.87\n",
      "Score with Elastic-Net penalty:          0.87 \n",
      "\n",
      "The accuracy of penalty = L1 and C = 1 is 87.09% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.56 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.89       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.82      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "The accuracy of penalty = L2 and C = 1  is 87.09% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.56 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.89       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.81      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "The accuracy of Elastic-Net and C = 1  is 87.08% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.56 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.89       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.81      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "C=0.1000\n",
      "Sparsity with L1 penalty:                32.12%\n",
      "Sparsity with L2 penalty:                0.00%\n",
      "Sparsity with Elastic-Net penalty:       19.79%\n",
      "Score with L1 penalty:                   0.87\n",
      "Score with L2 penalty:                   0.87\n",
      "Score with Elastic-Net penalty:          0.87 \n",
      "\n",
      "The accuracy of penalty = L1 and C = 0.1 is 87.00% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.57 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.88       653\n",
      "          24       0.87      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.81      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "The accuracy of penalty = L2 and C = 0.1  is 87.08% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.56 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.89       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.82      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "The accuracy of Elastic-Net and C = 0.1  is 87.02% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.56 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.86      0.92      0.88       653\n",
      "          24       0.87      0.79      0.83       485\n",
      "          25       0.93      0.90      0.92       765\n",
      "          32       0.95      0.83      0.89       388\n",
      "          35       0.75      0.81      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "C=0.0100\n",
      "Sparsity with L1 penalty:                81.25%\n",
      "Sparsity with L2 penalty:                0.00%\n",
      "Sparsity with Elastic-Net penalty:       64.93%\n",
      "Score with L1 penalty:                   0.86\n",
      "Score with L2 penalty:                   0.87\n",
      "Score with Elastic-Net penalty:          0.87 \n",
      "\n",
      "The accuracy of penalty = L1 and C = 0.01 is 86.35% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.62 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.96      0.97      0.96       730\n",
      "           5       0.83      0.92      0.87       653\n",
      "          24       0.88      0.77      0.82       485\n",
      "          25       0.92      0.88      0.90       765\n",
      "          32       0.95      0.81      0.88       388\n",
      "          35       0.74      0.81      0.78       393\n",
      "          36       0.83      0.86      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.79      0.81      0.80       616\n",
      "\n",
      "    accuracy                           0.86      5207\n",
      "   macro avg       0.86      0.85      0.86      5207\n",
      "weighted avg       0.87      0.86      0.86      5207\n",
      " \n",
      "\n",
      "The accuracy of penalty = L2 and C = 0.01  is 86.92% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.58 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.95      0.97      0.96       730\n",
      "           5       0.85      0.92      0.88       653\n",
      "          24       0.88      0.79      0.83       485\n",
      "          25       0.93      0.90      0.91       765\n",
      "          32       0.95      0.82      0.88       388\n",
      "          35       0.75      0.82      0.78       393\n",
      "          36       0.84      0.85      0.85       620\n",
      "          37       0.84      0.86      0.85       557\n",
      "          38       0.80      0.81      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.87      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n",
      "The accuracy of Elastic-Net and C = 0.01  is 86.58% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.6 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.95      0.97      0.96       730\n",
      "           5       0.85      0.91      0.88       653\n",
      "          24       0.87      0.78      0.82       485\n",
      "          25       0.93      0.89      0.91       765\n",
      "          32       0.95      0.81      0.88       388\n",
      "          35       0.74      0.81      0.77       393\n",
      "          36       0.84      0.86      0.85       620\n",
      "          37       0.85      0.86      0.85       557\n",
      "          38       0.80      0.82      0.81       616\n",
      "\n",
      "    accuracy                           0.87      5207\n",
      "   macro avg       0.86      0.86      0.86      5207\n",
      "weighted avg       0.87      0.87      0.87      5207\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.0010\n",
      "Sparsity with L1 penalty:                95.83%\n",
      "Sparsity with L2 penalty:                0.00%\n",
      "Sparsity with Elastic-Net penalty:       94.10%\n",
      "Score with L1 penalty:                   0.77\n",
      "Score with L2 penalty:                   0.85\n",
      "Score with Elastic-Net penalty:          0.82 \n",
      "\n",
      "The accuracy of penalty = L1 and C = 0.001 is 78.32% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.98 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.85      0.94      0.90       730\n",
      "           5       0.74      0.86      0.79       653\n",
      "          24       0.64      0.55      0.59       485\n",
      "          25       0.86      0.73      0.79       765\n",
      "          32       0.95      0.72      0.82       388\n",
      "          35       0.73      0.74      0.73       393\n",
      "          36       0.78      0.83      0.80       620\n",
      "          37       0.76      0.79      0.78       557\n",
      "          38       0.74      0.77      0.76       616\n",
      "\n",
      "    accuracy                           0.78      5207\n",
      "   macro avg       0.78      0.77      0.77      5207\n",
      "weighted avg       0.79      0.78      0.78      5207\n",
      " \n",
      "\n",
      "The accuracy of penalty = L2 and C = 0.001  is 85.48% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.77 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.89      1.00      0.94       730\n",
      "           5       0.82      0.90      0.86       653\n",
      "          24       0.89      0.72      0.80       485\n",
      "          25       0.92      0.88      0.90       765\n",
      "          32       0.96      0.77      0.85       388\n",
      "          35       0.77      0.81      0.79       393\n",
      "          36       0.83      0.85      0.84       620\n",
      "          37       0.84      0.84      0.84       557\n",
      "          38       0.78      0.81      0.80       616\n",
      "\n",
      "    accuracy                           0.85      5207\n",
      "   macro avg       0.86      0.84      0.85      5207\n",
      "weighted avg       0.86      0.85      0.85      5207\n",
      " \n",
      "\n",
      "The accuracy of Elastic-Net and C = 0.001  is 82.47% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 0.89 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.86      0.94      0.90       730\n",
      "           5       0.75      0.85      0.80       653\n",
      "          24       0.94      0.64      0.76       485\n",
      "          25       0.86      0.85      0.86       765\n",
      "          32       0.96      0.75      0.85       388\n",
      "          35       0.77      0.83      0.80       393\n",
      "          36       0.81      0.84      0.82       620\n",
      "          37       0.81      0.83      0.82       557\n",
      "          38       0.77      0.79      0.78       616\n",
      "\n",
      "    accuracy                           0.82      5207\n",
      "   macro avg       0.84      0.81      0.82      5207\n",
      "weighted avg       0.83      0.82      0.82      5207\n",
      " \n",
      "\n",
      "C=0.0001\n",
      "Sparsity with L1 penalty:                99.48%\n",
      "Sparsity with L2 penalty:                0.00%\n",
      "Sparsity with Elastic-Net penalty:       98.61%\n",
      "Score with L1 penalty:                   0.24\n",
      "Score with L2 penalty:                   0.75\n",
      "Score with Elastic-Net penalty:          0.34 \n",
      "\n",
      "The accuracy of penalty = L1 and C = 0.0001 is 24.66% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 2.1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.27      0.99      0.43       730\n",
      "           5       0.00      0.00      0.00       653\n",
      "          24       0.00      0.00      0.00       485\n",
      "          25       0.18      0.50      0.27       765\n",
      "          32       0.00      0.00      0.00       388\n",
      "          35       0.00      0.00      0.00       393\n",
      "          36       0.00      0.00      0.00       620\n",
      "          37       0.40      0.33      0.36       557\n",
      "          38       0.00      0.00      0.00       616\n",
      "\n",
      "    accuracy                           0.25      5207\n",
      "   macro avg       0.09      0.20      0.12      5207\n",
      "weighted avg       0.11      0.25      0.14      5207\n",
      " \n",
      "\n",
      "The accuracy of penalty = L2 and C = 0.0001  is 76.42% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 1.4 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.65      1.00      0.79       730\n",
      "           5       0.74      0.73      0.73       653\n",
      "          24       0.97      0.49      0.65       485\n",
      "          25       0.78      0.84      0.80       765\n",
      "          32       0.98      0.52      0.68       388\n",
      "          35       0.79      0.68      0.73       393\n",
      "          36       0.79      0.81      0.80       620\n",
      "          37       0.81      0.80      0.80       557\n",
      "          38       0.75      0.78      0.77       616\n",
      "\n",
      "    accuracy                           0.76      5207\n",
      "   macro avg       0.81      0.74      0.75      5207\n",
      "weighted avg       0.79      0.76      0.76      5207\n",
      " \n",
      "\n",
      "The accuracy of Elastic-Net and C = 0.0001  is 35.32% \n",
      "\n",
      "The log loss of Logistic Regression prediction is 2.0 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.34      0.98      0.51       730\n",
      "           5       0.00      0.00      0.00       653\n",
      "          24       0.00      0.00      0.00       485\n",
      "          25       0.22      0.60      0.32       765\n",
      "          32       0.00      0.00      0.00       388\n",
      "          35       0.00      0.00      0.00       393\n",
      "          36       0.82      0.33      0.47       620\n",
      "          37       0.68      0.67      0.67       557\n",
      "          38       0.41      0.13      0.20       616\n",
      "\n",
      "    accuracy                           0.35      5207\n",
      "   macro avg       0.27      0.30      0.24      5207\n",
      "weighted avg       0.30      0.35      0.27      5207\n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAIaCAYAAAApyCWzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebxV5Xn3/+/NfJhnZEZGQZmPCioS42xGY5oO6ZDnl0HzNK+2r/7aNCZNYpImTfOkgxna5Nfm6VNjEjVPa9pqM9k44nhAQVQEQRBQEZB5EIH798c53Fz3xVmLfQ57w8H9eb9evLjWuddea+2j5+I+a137ukOMUQAAAEA96HSqLwAAAAA4WZj8AgAAoG4w+QUAAEDdYPILAACAusHkFwAAAHWDyS8AAADqBpNfAACAt4AQwodCCA/V4LgfDCH8otrHPVWY/AIAAJxGQghrQwj7Qgi7zZ9vVenY40IIMYTQ5cjXYow/iDFecQLHutt9/dYQwk0VHmNtCOGytp67DJNfAACA08+7Yoy9zZ9PnOoLKjEvhHDhqb6II5j8AgAAvAWFEG4OIawPIewMISwOISwwY+eFEJpaxjaFEP6mZeiBlr+3t9xRnu/LKUIIZ4cQfhlCeL3ltZ8+zqV8TdJflFznO0MIT4UQtocQHg4hzGj5+vcljZH0ny3X8sn2fB88Jr8AAABvTU9ImiVpoKQfSvpxCKFHy9jNkm6OMfaVNEHSHS1fv7jl7/4td5QfsQcMIfSRdI+kn0kaIWmipP8+znV8W9Lk1soXQghzJP1vSddLGiTpu5L+I4TQPcb4O5Je0tG73F+r/K0XY/ILAABw+vlJy53SI38+6neIMd4aY9waYzwYY/xrSd0lTWkZflPSxBDC4Bjj7hjjoxWe952SXo0x/nWMcX+McVeM8bHjvGa/pC+r9bu/H5X03RjjYzHGQzHGf5H0hqR5FV5PmzH5BQAAOP28N8bY3/z5R79DCOH/DSE8F0LYEULYLqmfpMEtwx+WNFnSihDCEyGEd1Z43tGSVrc24D6AN8YN/6OkYSGEd7mvj5X0/9qJfMs5RlR4PW3W5fi7AAAA4HTSUt/7Z5IulfRMjPFwCGGbpCBJMcZVkn4zhNBJ0vsk/d8QwiBJ8TiHXi/pN1sbiDH2dtcwzoy9GUL4gqQvSXrGHe/LMcYvF5zveNfTZtz5BQAAeOvpI+mgpM2SuoQQPiep75HBEMJvhxCGxBgPS9re8uVDLfsfljS+4Lh3STojhPBHIYTuIYQ+IYTzK7ym76u59OIq87V/lHRDCOH80KxXCOEdLbXFkrSp5FrahckvAADA6ec/XZnBnW7855J+KmmlpHVqrrtdb8avkvRMCGG3mj/89hstNbx71Vyfu6ilDCGrvY0x7pJ0uaR3SXpV0ipJl1RywTHGQ5I+r+YP4B35WpOa636/JWmbpBckfci87C8l/XnLtfxJJec5nhBj1e8mAwAAAB0Sd34BAABQN5j8AgAAoG4w+QUAAEDdYPILAACAusHktwpCCP8nhFC4ZjUAnArkJgA4VoeY/IYQ1has99wthPB/W8ZjCOFtp+Dy2iSE8LYQwoZTfR0ATlxJbpoXQvhlCOH1EMLmEMKPQwjDT8U1VorcBJweivLOKbiO74QQPnuqr6MWOsTk9zgekvTbau4lBwAdwQBJ/5+kcWpemnOXpH8+lRcE4K0nhHBOCOHnIYQtIYSa9aYNIXwohPCQ/VqM8YYY45dqdc6C67g0hLAihLA3hHBvCGFsyb73hRD2mz7Hz1d6ng49+Y0xHogx/l2M8SE1rzpSquUb8ZchhMdb1rH+9xDCQDM+L4TwcEuj5KX2TnLLa78UQlgUQtgVQvhFCGGwGf9xCOHVluM+EEI4u5Xz91JzQ+kR5j/GiJb/iIPMfnNb7hZ1bf93B8CpEmP8aYzxxzHGnS0N4b8l6cKi/clNANrpTUl3SPpwew8QQuhSvcupnZa89m+SPqvmRTCaJN1+nJd9IsbYu+XPlErP1aEnv+30u5L+H0kj1Lys3zckKYQwUtLdkv5Czd/UP5H0ryGEIea1vyXpf0gaKqlbyz5H/FTSpJaxJZJ+4E8cY9wj6WpJL5v/GC9Luk/SB8yuvy3pthjjmyf6ZgF0CBcrX6u+NeQmAG0SY3w+xvg9HT+/ZFpKJ/4shLBM0p4QQpcQwqdCCKtbfol+NoRwbcu+UyV9R9L8ll+Mt7d8PfvMQAjhoyGEF1rKvf4jhDCieu9UkvQ+Sc+03FjYL+kmSTNDCGdV+Txvycnv92OMy1uS/WclfSCE0FnNSf2/Yoz/FWM8HGP8pZp/q7jGvPafY4wrY4z71Pyb1qwjAzHG/x1j3BVjfENH/4P0q/Ca/qXl/Gq5lt9U8/rWAE5zIYQZkj4n6U+Psyu5CcDJ9JuS3iGpf4zxoKTVkhZI6ifpC5JuDSEMjzE+J+kGSY+0/GLc3x8ohPB2NS8z/AFJw9W8XPJtRSdueYpV9OdTBS87W9LSIxstuXJ1y9eL/GVLScii0IbPhb0VJ7923ep1krpKGqzmurxfs/8BJF2k5v+IR9i64r2SekvN/yiEEL7a8hvTTklrW/YZrMr8u6RpIYTxal4Pe0eM8fE2vi8AHUwIYaKa77z+YYzxwePsTm4CcDJ9I8a4vuWXZrXcUX255Zfs2yWtknRehcf6oKT/HWNc0vKL9o1qvlM8rrWdY4z9S/58teAcvSXtcF/bIalPwf5/Jmm8pJFq/gzGf4YQJlTyZk6LOpA2Gm3iMWqul9mi5n94vh9j/Gg7jvlbkt4j6TI1/+PST9I2SaGVfY8pSI8x7g8h3KHm/3nOEndWgNNeaP4gxj2SvhRjrORnmtwE4GSyv3ArhPC7kv5YzR/UlZonm5X+ojxCzWVVkqQY4+4QwlY1TzzXnuiFttgtqa/7Wl81f6D4GDHGx8zmv4QQflPNT8y+ebwTdaQ7v11DCD3Mny6SFELoHkLo0bJPt5ax1hL7Eb8dQpgWQugp6YuS/m+M8ZCkWyW9K4RwZcvdkh6hufXPqAqurY+kNyRtldRT0ldK9t0kaVArjx1vkfQhSe9uuRYAp4djclNLne6vJH07xvidCo9DbgJwMqVfeFt+Wf9HSZ+QNKiltGG5jv6ifLxOEi+r+SnVkeP1kjRI0sbWdjYfrG3tz6cLzvGMpJnuHBNUeb1zVOu/+B+jI01+/0vSPvPnppavP9+yPVLSz1viwtYXar5z8X/U/Jiwh6Q/kKQY43o13yH5tKTNav6N6E9V2ffgFjU/ptwo6VlJjxbtGGNcIelHkta0PMIc0fL1RZIOS1oSY1xbwTkBdAyt5aaPqPlx2+dtUj/OcchNANokNOuh5g+6quWX4+7tOFQvNU8ON7cc539IOseMb5I0KoTQreD1P5T0P0IIs1rO/xVJjxXlDPPB2tb+FP2Sfqekc0II17W8589JWtaSuzIhhP4tNwyO3JD4oJo/ePzz430jJCnEWLO2cSddCOE+SbfGGP/pVF9La0IIv5L0w456fQBqg9wEoFIhhLWSPhJjvKelpvZFt8u6GOO4So9hvvZlSR9X8y+7t0iaq+aSq39qmfTeKWm+pMMxxsEhhP8jaUOM8c9bXn+Dmn8xHyDpYUk3xBirunBOaF7c41tqvsn5mKQPHZlgt9wxXhBjvDo0d8P5LzWXax2StELSZ1s+MHz88zD5PTlCCOdK+qWk0THGVutXALw1kZsAoOPoSGUPb1khhH9R8wdj/oh/XAB0FOQmAPXoLXXnFwAA4K0uhDBGzXX+rZkWY3zpZF7P6YbJLwAAAOoGZQ8AAACoGzVZ5GLAgAFxxIijSz7v2nW0lGzIkCHZvmUtew8fPly438GDB1PcuXPnbKxTp6NzenuM453Ps3fFDx06lI3Z7TfeeCMb69eveGXRxYsXp3jOnDkVX8uSJUu2xBiHHH9PAGXIT9XNT+vWrdOWLVsqv3AArSI3nbzcVJPJ74gRI3T77ben7fvuuy/FN9xwQ34BXYovYe/evSm2/1Ekafv27Snu1atXNtanz9GV8Pbt25eN+f/Ylj/H/v37U7xnz57C869evTobu+aaa1Ls/wey53/44YcLr8WXozQ0NKwr3BlAxcry0/XXX5/tW5afbG6pVn6yx/H/2Pht+w/H7t15i+EdO46uEOrz09VXX51in2dsflq0aJEqceGFF1a0H4ByHTk3tXfu1JbcVOncqRq5ibIHAAAA1I2a3Pn1Pv7xj6fY/xZw4MCBFPvb+vb2uP+t45FHHknxFVdckY2tWHF0MZApU6ZkY/ZOx+uvv154PkkaOnRoinv37p2N2Wv153jxxaP9qEeNylco3bx5c4r9b272Pdr3B6B27NOo9uYnf+fDPtXx+em5555L8VlnnZWNnez8NHLkyGysLD/ZbZuf7BM6ANVj5062BEKS3nzzzRQPHjw4GyvLTafL3KnWuYk7vwAAAKgbTH4BAABQN2pS9tDQ0KBp06al7TvvvDPF73jHO7J97af7/K3zhoaGFC9ZsiQbu/baa1NsH01K+aNEP2Zv3Zc9KpDygmtfdvH888+n2BZ3S9KsWbNaPZ8k9e/fv9XjS/ljjUGDBglA9bUlP9mf17L8ZD+JLEnve9/7Uuxz0NSpUwvHbE7w+cl+Stvv6/PTypUrU+w/UT1jxgwVse/X5y77QRmbn8o+CAOgcrXITdWaO5XlprbMnWxuau/cqRq5iTu/AAAAqBtMfgEAAFA3mPwCAACgbtSk5vfgwYPaunVr2r7uuutSvG3btmP2PcI3XLZ1I35Fj/Xr16e4e/fu2ZitcRs9enQ2ZtuDfOtb38rGPvGJT2Tbtk2Gr2kZM2ZMinv27JmN2SbOvqbFtvnwNXz2OP51AKqjLD/5Fj42X/iWPWX56aWXXkpxjx49srGTnZ9s/Z9U/fzk6+8AtE9bclOlc6fZs2dnYx1p7tSW3GTrjKuRm7jzCwAAgLrB5BcAAAB1o2YrvNl16JuamlLc2NiY7WdvS9vVPaT89rhnV07zLTnsrfynn346G7NthuyKIa1tl91mt48H/AoqTz31VIpnzpyZjdlHB/Z7JEmvvvpqisvaEQGonieeeCLF5557bjZmHx+uWbMmGxs7dmzhMe0jQ99qzJZB+PxkWw2dSH6yj/58u5+y/GRzqc9rr7zySoptfvKPLgG0X7XnTn6e0ZHmTtXKTUVzp7LcxJ1fAAAA1A0mvwAAAKgbTH4BAABQN2pS89ulS5es5qOs/sMu6Tt+/PhsbN++fSnu2rVrNmbrWHzdyL333pviSy65JBuzdTJf+MIXsrFNmzZl2zfeeGOKb7jhhmzMbvt2GraVyJYtW7IxW+8ycuTIbMzWtIwYMUIAqq9Lly5ZSy8b25p8Sdq9e3eKJ0yYkI1Vmp+6dMnTbHvzk61rk/L8dP3112djH//4x1s9ppS3YWtLfrLfG5uf/DEAtE+9z53am5uK5k5luYk7vwAAAKgbTH4BAABQN0ItVueZNm1a/P73v5+2V69eneIPfOAD2b62fc5zzz2XjU2ZMiXFTz75ZDZmVy2xx5DyVkL/63/9r2zs/vvvT/HatWuzsddeey3bto9DbTskSRo0aFDh+S+44IIU+0cVL7zwQoptWyMpv3XvH1V06dJlcYwx73UCoM2mTZsWb7nllrRt89Ov//qvZ/u+/PLLKV6xYkU2Nnny5BTbFj3Syc9Pjz/+eDZmH5eW5Sdf5rFq1aoU29ZGfl+bn84//3w1NTXl/ZQAtNnpmpt82cPQoUNTXK2508qVK1NcjdzEnV8AAADUDSa/AAAAqBtMfgEAAFA3alLzO3PmzPjTn/40bdvWE88//3y2r12Gz7bukPLaEL8Mn61/s7VvknTXXXel+D3veU82Zpfvs+1AJGnv3r3Ztm1ZNmvWrMJ9bZ2MlC+JunXr1mxs4MCBhefv1q1b4TFDCNT8AlVQlp987ZzNT7btmVT7/OTzkd/esGFDisvykz2mlLcXakt+srV0dtnQxsZGan6BKmjL3MkuoX665qZaz53KchN3fgEAAFA3mPwCAACgbtRkhbfOnTurb9++advexr/iiiuyfW07i379+mVjGzduTLF/dNep09F5u10VRMrbqf3BH/xBNmZbgLz73e/OxvyqIdu3b0/xkiVLsjG7cohdeUSS3vWud6W4V69e2Zh9rGBbjkjKvmef+cxnBKD6yvLT5Zdfnu1baX6yj92kk5OfduzYkeJa5Cf/uNK+/z//8z9PsX3ECaD9apGbTsXc6VTmps9+9rMpLstN3PkFAABA3WDyCwAAgLrRrslvCOHpal8IAAAAUGuFrc5CCO8reo2k78QYhxSMa9KkSfHmm29O2wsWLEjx5s2bs31t3crEiROzMbt8X+/evbMxu0zwGWeckY3ZJQF9Xe3OnTtTbFuFSNKhQ4eybVuP4pcbtrUy48ePz8ZCONpZw7cgsdt2CVL/uj179mRjffv2pdUZUAU+P1100UUptvVoUr5s5qRJk7Ixm598fZrNT8OHDy8cmzNnTjZma+VsmzXp2OU+y5ZDt/npzDPPzMZszV9785Pdb+HChXryySdpdQacoLbMnSrNTX7uZJcw97mpvXOn9uamWs+dFi5cqCVLlrSam8o+8Ha7pB9Iam123KOVrwEAAAAdWtnkd5mkr8cYl/uBEMJltbskAAAAoDbKJr9/JGlnwdi1ZQft2bOnZs6cmbYfe+yxFNvb+FLehmPp0qXZmL21/vDDD2djV111VYrtqiCSNHTo0BT7RwV33HFH4evuu+++bNs+Du3SJf9WDRgwIMW2rYiUl0/YR4xS/njUl5zYFe7s408A1dPQ0KAZM2akbZufLr744mxf28Js2bJl2ZjNT4888kg2duWVV6bY5xm7qpLPTz/+8Y8LX9fe/GQfgUr5I8rOnTtnY+3JT75cDED7lOWmas2dKs1NvgTsZMydqp2bfDmGVTj5jTE+WDLWVHhEAAAAoIOi1RkAAADqBpNfAAAA1I3CVmcnYvbs2fH+++9P23a5vv3792f7ltWL2VZjfvlQ20rDtvyQ8noQ3wbNji1atMhfd7ZtW3T4GpdNmzaleMSIEdmYfY/79u3Lxmw9sq/rtS1J7PElaeTIkbQ6A6pg9uzZ0dao2aUx/c+r/7m3yloh2vzk687sMX2robbkJ1tL5/O4zR/+HDY/+Xxs85Nd3l2S+vTpk+JXX301xddcc42WLl1KqzPgBJXNnaqVm+x86XSdO5XlJnv8q6++ujA3VXTnN4Twdvs3AAAAcDqqtOzh6+5vAAAA4LRTUdlDCGFJjHFOCOHJGOPs4+3fp0+fOGvWrLT90EMPpdifz26/9tpr2Zi9zV32OvuIUcpLJOxqIpI0bty4FPsVRPxKKPYcfsW1nj17pviJJ57Ixhobj1Yn+DYftszDP3KwKz+dc8452VgIgbIHoArK8pN/RGdzgG9LZtsCefY4/ue8vfnJryJnle37+OOPZ2Pnnntuin1+siUavlzDrgw1ffr0FDc2NqqpqYmyB+AEtWXuZHPMqc5NZXOnstzUlrlTtXMTH3gDAABA3WDyCwAAgLrB5BcAAAB1o2x5Y+tI0cau0r1aTJkyRQ8+2PoCcb42xdZ/2BpfKa/r8K+zLTJCyEs61q5dm+Lx48cXXqevU/HLgNo2I6+88ko2NmzYsBTPmzcvG9u58+iq0L5Fm21jcumll2ZjEyZMSLGvfwZQHVOmTNEDDzyQtm3+8HnG1vb7Ojqbn/xSoLa9mK+rK8tPtlbO1/j6HGTzk209JuW5dP78+dmYzU++DZLNT5dddlk2NnHixBTb/FS2hCiAylVr7mRzjs9Ndu7kf3YrzU1tmTuV5aZqzZ3ak5squvMbY7zY/g0AAACcjih7AAAAQN1g8gsAAIC6UWnNb5scOHAg6xE3duzYFPtedbY25ZFHHsnGbM+3wYMHZ2NldWu2H51fQtj2nBs1alQ2VtYb76abbsq2v/nNb6b4+eefz8Zs/YmvR7Y96Dp1yn/3aGhoSHGPHj0KrwVA+/n8ZPOF7/Nra8YeffTRbKzS/ORr12w+9Mt02vw0evTobKy9+WnFihXZ2KRJkwqPM2PGjBT73GXzU/fu3VPs+3ECaJ8DBw5o3bp1advmppMxd+rIuak9c6ey3FR45zeEMDGEcGErX18QQpjQ2msAAACAjqys7OHv1Hp3h30tYwAAAMBppex51bgY4zL/xRhjUwhhXNlBQwjZYzF7u96XCNjb3HZZPym/Je8fwT311FMptst1StI999yT4re//e3ZWP/+/VNslxqWjr2Vbtt+/OAHP8jG7HsaNGhQNrZ///7Cc5S1QLKPR/37BVAdIYTs0ZgtdVi5cmW278nOTwMGDEixb9Pjz2Efj956660qMnDgwGz7jTfeSLHPT2eccUbh+Tt37pxinysBnDifmzrS3MnmJp83TnVuas/cqSyDlRWdNpSMAQAAAB1S2eT3iRDCR/0XQwgflrS4dpcEAAAA1EZZ2cMfSbozhPBBHZ3sNkrqJunaWl8YAAAAUG2Fk98Y4yZJF4QQLpF0TsuX744x/uq4B+3SRf369UvbtqZuypQpha/z7b1sTaxvu3H++een2NaXSNLll1+eYr/snq2FsUvwHbluy7YI8UuL7t27N8V9+vTJxuzSx75uxS7RZ9+DlNe7bNu2TQCqryw/TZ48ufB19nMMUuX5yX52QMrz08aNG7MxW7t2vPxkP2vg89O+fftS3Jb8ZJd99vnJfpbBvl//2QUA7eNzk/359HMnWw9ci9xUrbmTX964vXOnstxUNHcqy03HbdAYY7xX0r3H2w8AAADo6PjILgAAAOpGzZbmsa1w7O35LVu2ZPvZ29W+7YW9ld+7d+9szB7Tlz3YVUPOOuusbMy2yFi1alU25h8r2LZoPXv2zMbsI0D/COCxxx5LsW9BYldeKVvFzbZEA1BdRa26tm7dmm3bn3Pf0tDmp169emVjJyM/2dZD/vy27ME+RpUqz0/+UapFfgJqoyg3+blTpbmpo82dqpGb/NzJvqdKcxN3fgEAAFA3mPwCAACgbjD5BQAAQN2oSc1vjFEHDhxI20uWLEnx/Pnzs31t+wzflsLWA9s6ESmvI7HL3kl5vYt/na2T8XUqdkzK2w7ZWJI2b96cYvtepbw2xS4JKuUtQfbs2ZON2dYe9nsmSXPmzBGAE9eW/GRb9rQlP9kaXJ+fbC7xr7Pbvu1aWX6yeVTK85O/7rlz56a4LD/ZlkRSXvNnv2cf/OAHBeDE1SI3+Z/jsrnT6ZKb/NypPbmJO78AAACoG0x+AQAAUDdqUvZw+PDh7Lb7ggULUuxXLrMlCrt27crGbAsx2zpDylsS+dWN7C35hoaGbMzeOm9qaip8nd/Xtxl54YUXUnzRRRdlY/Y9+scBI0aMSLFvTxRCEIDa8vnJ/vz61ZDs47vdu3dnYzY/2bZjUp4v/ApHkyZNSrFv2WNzzuLFi7Oxsvzk86rNTxdeeGE2Zt8j+QnoOGoxd2pLbrI5plq5yefUjjJ34s4vAAAA6gaTXwAAANQNJr8AAACoGzVb3tguN/fMM8+keNq0aYX7vfbaa9nYsGHDUnz48OFszNYA+zZgdsm+F198MRsbNWpUis8+++xszC/DZ+tI1q9fn43ZWpyHHnooG7M1dr5dh23tsWHDhmzMLufnxwBUj807zz77bIqnTp1auN/JyE+jR49OcVvyk88XtpbO5yc71t78ZPNh2TLIANqmaO7kc5NVrdz00ksvpbhWc6eOkpu48wsAAIC6weQXAAAAdaMmZQ8HDx7U66+/nrbPOeecFPsVPWw7izPPPDMbsyud+Fvgdtu2zpDyxwb2MaKUt+Do1Cmf+69atSrbHjRoUIr79euXjW3atCnFF198cTZm37tfGc6uTDJu3Lhs7Mtf/nKK7SooAKqnvflp/Pjx2ZjNTz6X2DyzevXqwmsZM2ZMtm3z2vHy08CBA1Nclp8WLlyYjVU7P9nVlQC038mYO5XlprK501stN3HnFwAAAHWDyS8AAADqBpNfAAAA1I1gazyqpWvXrtHWfPzkJz9J8bx587J97fnvu+++bGzHjh0pvvrqq7MxW/9x0003ZWN/8zd/k+KdO3dmY7ZOZvjw4dlYWU2Nt3fv3hTb+hopr+Pz3981a9akeMKECdlY2X+Lzp07L44xNhbuAKAibclPtk3Q/fffn43Z/HTVVVdlYzY/feELX8jGyvLTvn37Uuzzk69fa29+8rV8ls1Pvsa5yHnnnaempibWPgZOUC3mTj432dzQlrmTzU12qWHp5M+dqpGbuPMLAACAusHkFwAAAHWjJmUPY8eOjTfeeGPavv7661O8fPnybN/p06enePfu3dlYr169UmxXDJGkpUuXpti3+Whqakqxb0Nm23y88cYb2Zi9rS5JU6ZMSbF/5Ggfh/bo0SMbs7f8/ffX7usfFdhWIr49SQiBsgegCnx++tjHPpZiu6KSlOenXbt2ZWM2P/nWPzY/+bY8Nj/5Vj/tzU8+l9i8U5af/OpPDQ0NhccsanV07rnnUvYAVMHpOnfyLdPOOuusFJ/KuVNjYyNlDwAAAACTXwAAANQNJr8AAACoGzWp+Q0hbJa0ruoHrm9jY4xDTvVFAKc78lPVkZuAKiA3VV1hbqrJ5BcAAADoiCh7AAAAQN1g8gsAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtMfgEAAFA3mPwCAACgbjD5BQAAQN1g8gsAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtMfgEAAFA3utTioAMGDIgjRoxI27t27Urx0KFDKz5OjLFw7NChQynu1Cmfw9ttf4wQQrvOb8/nt994441srG/fvoXHXLx4cYrnzp1b0bklacmSJVtijEPKrxjA8ZTlpyFD8h+xsnxx+PDhwv0OHjyY4s6dO2djNj/ZYxzvfF5781O/fv0Kj2nz05w5cyq6jnXr1mnLli2VXziAVnXkuVMZn7dsXvM5rhpzp2rkpppMfkeMGKHbbrstbd9///0p/sQnPlHxcd58880U+2/u9u3bU9yrV69srKGhIcX2HyHp2P/YZWP79+9P8Z49ewrP/8ILL2RjV155ZeE57AnHyUMAACAASURBVPt47LHHCvfz/+N17dp1XeHOACo2YsQI3X777Wn7vvvuS/H111+f7dulS3GK3LdvX4p97ijLT3369Gn1GP44Puf5bfsPx+7du7OxHTt2pHj16tXZ2NVXX51in2fsRH3RokWqxIUXXljRfgDKleWmj3/849m+/pdqy85d2pKb7LafmJadr71zJ5+brrrqqsJz2Pz3yCOPFI7ZnDZ//vziay4cAQAAAN5imPwCAACgbtSk7CGEoG7duqVtW+rgb4EfOHAgxQMGDMjGbMmCPZ6UP5Lzt8ptGcLEiRMLr9PefpeOrZsbNGhQinv06FE4NmHChGxs/fr1KR41alQ2tm3bthSXPUZ44oknCscAVM8NN9yQYl8+YEuvBg8enI2V1c7Zx3JXXHFFNrZixYoUT5kyJRuzj+xef/31wvNJeQ1g7969szFbu+zP8eKLL6Z45MiR2djmzZtT7Es+bL569NFHU7x3714BOHEhhOzn7Pd///dTbOt/pTw32fmIVJ6bHn744RT7Es2VK1emePLkyYXXebzcZPNPz549C8cmTZqUja1bd7S608+dtm7dmmKfm+x7tOWkZbmJO78AAACoG0x+AQAAUDdqUvbQo0eP7FHbv//7v6f4He94R7av/7ShZbs22DYXkvSe97wnxb6Vhi118GP2sWL//v0Lz308zz77bIrtJxul8jYc9pz+k9a2JGTgwIHtvjYAxRoaGjRt2rS0feedd6bY5yf78+of7dn8tGTJkmzs2muvTbEt7ZKks846q3DM5itfZuE719h9fQnVqlWrUuzz04wZM1SkLD/ZDhL2MWtZ+RaAyvXo0UNTp05N22W5ybYF8z+rZbnpve99b4p9TrGlDmX5xs9P/Pnttu9S89xzz6XY56bZs2erSFlu2rlzZ4ptbirr1sOdXwAAANQNJr8AAACoG0x+AQAAUDdqUvN76NChrI2Yrc/17Tq6du2aYt9OzPJ1tK+88kqKfRs0uzKJXSpQymtFvvvd72ZjfnUnW4/n6/1se7Pu3btnY7Zdkq9psXV8vqbGtgTxq6sAqI6DBw9mbXOuu+66FPsWPvZn1H8+wdbA+Vo12+7Q5wf7sz169OhszLYv+vu///ts7H/+z/+Zbds2Pj4/2ePa+j8pr931eabS/GTzWluWQQVQzOcm+9kB+3N7ZN8jfDsxy+emjRs3prhs7uRbjdkc8w//8A/ZmF99zuYHn5vGjRuXYp+bbO1ue+dO9nX+M18Wd34BAABQN5j8AgAAoG7UpOzBe+qpp1I8a9aswv1eeumlbHvMmDEp9u0yhg8fnmJ/W9223rFtNSRlbUQ2bdqUjdnV16R8xTl/+9w+HvDX9vTTT6f4nHPOycbsI0K/8oot5bCtmABUl/2ZbWpqSnFjY2O2n/25tyujSXl+8uwjQ9/OzD5qtLlCytugvfbaa9mYXX1NKn8MaPOTb0Vm8/HMmTOzMXutZfnJtkvzjy4BtJ/NTbZNWVkL1bVr12bbZXMnu6qjLbOS8jLU5cuXZ2N27uRzky3VkPJ2Yz432Rzjr23ZsmUpnj59ejZmj1OWm+ycqyw3cecXAAAAdYPJLwAAAOoGk18AAADUjZrU/Hbu3Dlbiq6szte2PvM1dLbGo2yZOl83cv/996d44cKFha/73Oc+l21v2bIl277xxhtT/Pu///vZ2Mc+9rEU+1Y/L7/8coptyzcpb8NxxhlnZGO2Fsa3GQFQHV26dMnqZW3sa+Bs28Lx48dnY/v27UuxrZWT8pzka27vu+++FF9yySXZmM0lN910UzbmP6Pw6U9/OsW+TaNtPeTzk/1shc95tlbY1gZK+ffGtlLz1wWgfbp06ZItHWxj/7kjO3ey7cOk/OfY5ybL187a3PS2t72t8HWf//zns21fA2znTjfccEM2Zrd9btqwYUOKfdtJ+57sZ76kPDfZuZO/Los7vwAAAKgbTH4BAABQN0ItVueZNm1a/MEPfpC216xZk2K7mpKUPzJ7/vnns7HJkyeneOnSpdmYLaWwZQZSvlLcX/3VX2VjtiTCty7yjwDt49DFixcXjtk2G5I0b968FPtHFatWrUrxlClTsrGyMo8QwuIYY96HCUCbTZs2Ld5yyy1p2+anD3zgA9m+9mfbt020+cm26JHyFmI+P9j89PWvfz0bK8tP/hHekCFDUvzEE09kYzY/+fx4wQUXpNiXedj8ZFsb+X3to9Tzzz9fTU1Nee0ZgDabNm1avPXWW9P26tWrU/xrv/Zr2b6vvvpqilesWJGNVTp3KstNX/va17Kxstzk2zBWmpv8+W1u8i3SbG6yLSGl4tx07rnnFuYm7vwCAACgbjD5BQAAQN1g8gsAAIC60a6a3xDC52KMXywanzVrVvzFL36RtocOHZriF154IdvXtjezbYWkvM2Hr02z9W+2hkSS7r777hS/5z3vycZs2yF/zD179mTb69evT7Ffas+2JbPLlXp+2T/7nmyrJCmvVWmldRI1v0AVzJw5M/70pz9N2yNGjEix/9yBbenl85NdwtMvYWzzk61/k6S77rorxT4/de/ePcV79+7Nxvy2bQvk20nafe0xpby9UFvyk81ztjawsbGRml+gCmbOnBl//vOfp23bDnXlypXZvmVzp0pzU1vmTnZOYlu2SuW5yS6F7l9r84iUf0aqvbnJxmW5qb13fj/SztcBAAAAp0zhyhEhhJ1FQ5IaanM5AAAAQO2UrfC2XdK5McZjlu8JIaxvZf+kU6dO6tOnT9q2JRBXXHFFtq9tZ9GvX79szLbo8aUFdmUSW54gSe973/tS/Id/+IfZmG2R4W/r+1VDduzYkWLfysi29vCPFa6++uoU9+zZMxuzjzz9o0r7/j/zmc8IQPV17txZffv2Tdu2BOLyyy/P9i3LTxs3bkyxLy2w+cmuqCbl7dR8fpo0aVKK3/3ud2djfsW1nTuP3p9YsmRJNmbbNvr89M53vjPFvXr1ysbsY0/brk3K3/9nP/vZFNtHnADaz+emn/3sZyluy9yp0tzk507vf//7U+xzk23N6nNT2dzpqaeeysbs3Mmu2iaV56b2zJ3KclNZ2cMtksYWjP2w5HUAAABAh1R45zfG+OclY39Wm8sBAAAAaodWZwAAAKgb7W11tiTGOKdofPLkyfGb3/xm2r744otT7JfotHUrEyZMyMbs0ne9e/fOxmzLNF9vYsfmzMkv09ai2BZHUt4CSCpeMk/K6/hsyxFJCuFoZw3fksO2U7PtSDz/up49e9LqDKiCSZMmxZtvvjltX3TRRSn2S5zb/DRx4sRszH4mwden2WVJbbsiPzZ79uxszNbx2jZr/lqkvJa3LD+deeaZ2Zit+fMtkuy2b4Nk85rdb+HChXryySdpdQacoMmTJ8dvfOMbaXvBggUp9ksI2/mJ/ayAlNf8+rlTe3OTnTuNGjUqG7MtyqTKc9O4ceOyMZtjfOtZu12Wm+x+CxYs0JIlS6rX6qxs4gsAAAB0VBVNfkMIA0MIA2p9MQAAAEAtlfX5HSPpa5IuVXPbsxBC6CvpV5I+FWNcW/TahoaGrE3Oo48+muKFCxdm+9pHcMuXL8/GbDnBI488ko3Zth++XMGuqOQfFdx+++2Fr3vwwQez7QsvvFBF+vfvn+JXX301GysrJfErmlh2lRT7iAFA9fTs2TPLT48//niK7WNGKW8T5Fv2lOWnK6+8MsX+kaDNT77M4sc//nHh6+67775s25ZrdOmSp/IBA47eq7DlGVJePmFXvJTy8g2fx3bt2pVim58OHTokACeuoaEhWxHNzp1s+aiUlxM8/fTT2ZgtmWpvbvJzpzvuuCPFPjfcf//92bbNTXaOJ+W5yZa2+uuxpQzSsW1jLVuGVWluKrvze7ukOyWdEWOcFGOcKGm4pJ9Iuq3kdQAAAECHVDb5HRxjvD3GmKbOMcZDMcbbJBV/UgsAAADooMpWeFscQvh7Sf8i6cgyIKMl/Z6kJ2t9YQAAAEC1FbY6CyF0k/RhSe+RNFJSUPMk+D8lfS/G+EarL5Q0Z86c+NBDD6VtW6th23NIx9acWHbpO98uwx6n7Ji2hsV77LHHsm2/ZJ49p7/OTZuOrvrsW6bt378/xb5l2cCBA1Ps2wzZliS+JdywYcNodQZUwezZs6Otn7VLY/qf1/bmJ9vqx7cosznXtxqyY4sWLfLXnW3bOl+fx9ubn4YOHZri7du3Z2N2yXr7OYdrrrlGS5cupdUZcILmzJkTH3jggbRt5wR+KeBaz52GDRtWeHxfR3wy5k62vZltCSnlucke/8orryzMTWUrvB2Q9A8tfwAAAIDTHiu8AQAAoG60a4W34+nTp0+0t8FtCUTZ+bZu3Zptl62AZvlb9/aW+/r167Mx2wLE31ZvaGgoPEfZvk888UQ2du655x7nipv5x6GrVq1K8dSpU7OxEAJlD0AV9OnTJ9qVH+1jRv+IzuYr3/qnrKTKHsfnp27duqXYrnYk5Sse+bIov4qcVbavz0+NjUfTiG+RZnNSWX6aPn16drympibKHoAT1KdPn2jLm2z71bK5U1tykz2OLc+SynPT2LFjU+xXX6tFbvIt0ux1+5xqV/WdNm1adryi3MSdXwAAANSNSld4e7v9GwAAADgdVXrn9+vubwAAAOC0U9bntzUV1XVNmTLlmKWCj9i2bVu2bes/fI1vWb2dbcnja2FWr16d4gkTJhRep6/xtS0yJKlv374p9svw2fP7Gl+7TLGtoZHyJUovu+yybGzixIkpfv311wuvG0D7TZkyJfs5tMto+jxj85Ovo7M1sX6Z4uHDh6fY16etXbs2xePHj8/GbC7zdXQ+B9n85JdYt/lp3rx52ZhtE+TbINn650svvTQbs/nJtmL0tcEA2mfKlCnZz6DlPxNVlpvssr4+p/n2itaaNWtSXDZ3qlZuOu+887IxWx/s5052CWWfm+y12lxclpuo+QUAAEDdYPILAACAusHkFwAAAHWj0prfI4UYuyrZ+cCBA9qwYUPatr11fX2u3X788cezsblz56bY17TYulpbsyfl9R++x9yuXUffgq3Lk/Ll8/xxP/e5z2Vj3/72t1Nse8xJeW2cN2PGjMIxW39nl0EGUD0HDhzIelja3rq+z6+tGXv00UezMZuffO6wecbX1dp+mX4JYds/c9SoUdlYWe/OL37xi9n2zTffnOLnn38+GyvLT7Z/r8+r9jMSPXr0SLHvFQygfQ4cOJCtTTBmzJgU+7mTrettS26yc6LOnTtnY/YzCDt27MjGbG7yyxKXzZ1uuummbOyb3/xmim3vcKny3OR7AHfv3r3VuCw3VXTnN8Z4sf0bAAAAOB1R9gAAAIC6UZPnVZ06dcoekdnb9bYNmZSXKNglkaVjb8lbK1asSLFdqlSSfvWrX6X47W/P1+Xo3bt34TH9+ey13nrrrYWv69evX7ZtH5X6x6i2zYcf87fyAVRfCCF7bG/zky8RmDRpUop9frKteHyJwFNPPZVi3wrxnnvuSbHPTwMGDEixb9Pjz2FLN2655RYV8SVUb7zxRorto1Mpb4Pkz2/zo78WACeuU6dOhbnJlwiU5SZfamXZuZNdTliS/vu//zvFPjfZeY4vwfBzF9vOsWzuZPOdlC+33Jbc1J7SK2ZbAAAAqBuFk98QwsQQwoWtfH1BCKG4+zEAAADQQZXd+f07td7dYV/LGAAAAHBaKSuUGBdjXOa/GGNsCiGMKzto586ds+XtbH1I2ZJ5fjk7WxPrWwLZVh62rZqU16rYZTilvBamT58+2ZivGxk2bFjhcWzbD/tepWOXabYeeuihFJ9//vnZmP0++WWgAVRHly5dsvo1W1s2efLkwtfZFjpSvmyxz0/2Z3vdunXZ2OWXX57il19+ORuz+cnnFZ+fbC2vX1503759KfZ5zuY1X1dnl1b1+Wn//v0ptu/XL98MoH383MnOgWyNr+dzk62J9bnJfgbBtlWT8mWD/bLEZXMnX2NsW5/53GTb1PocZ9s5+rristxUNHdq7/LGPUrGGkrGAAAAgA6pbPL7RAjho/6LIYQPS1pcu0sCAAAAaiP4W8tpIIRhku6UdEBHJ7uNkrpJujbG+GqrL5TU2NgYH3vssbRtW+T4W/D2UZovF7C30m0LDCkvkdi4cWM2Zh/5la0YUtY6xPNtyex19+zZMxtbvPjo7wa+BYl9RGhbmnittBJaHGNsbG1fAJWbO3dufOSRR9K2zU++3Mi2BfMtw+yjRpsPpDwn+LIHm5/OOuusbMw+pvP5acqUKdm2bS/k86M9h2/FaHNzWX7yec3ybSFjjPQ+A07Q3LlzC+dOPjeVzZ3s/MjnJtuG1pc92LzhS8DsHOh4ucnypQf2enzr2SeeeCLF7c1Nfu5UlJsKa35jjJskXRBCuETSOS1fvjvG+Kui1wAAAAAd2XE7A8cY75V070m4FgAAAKCmWOQCAAAAdaMmyxvHGLP6DFtfd+GF+boZ/fv3z15n2WPY9hhSXtNil72T8joZ34bH1rT4Gl+/r6059sv37dy5s/DabBs2z16br8WxtTHLluVd5mbMmFF4TACVizFmNbJPPvlkiufNm5ftW/a5A1sPbPOKlNek+fxkc5d/XVnNnc8X9ji+1dDmzZtT7POazU++dte2U/N5zeanJUuWpPiDH/ygAJw4n5vs54cuuOCCbF/7GQTfstAew+cYW/Prc5PNIza/+eO0JTf5Fo127uRfZ3OTn3NVmpvs0vK/9Vu/pSLc+QUAAEDdYPILAACAulGTsofDhw9nt8wvuuiiFNtb3lLeLsiP2RY9tjxCknbs2JFi367Dtg/yjwPtrXP76E46tgzC7mvPJ0krV65M8cUXX5yN2XZu/ra+fcxQ1uqsqAUdgBPj85MtxfKtGO3ju927d2djdnUin5+2bNmSYr9Skn1k6HOAzTn2kad/nd/Xt0FavXp1iv3j0rL8NGLEiBT7dkL+MSSA6ooxZrlpwYIFKfa5yc6ddu3alY3Z3DRgwIBs7PXXX0+xX2HStizzq8aV5aayuZPPTS+88EKK7fvz+7YlN1l27lQ2jyKbAQAAoG4w+QUAAEDdYPILAACAulGTml8pXwpvxYoVKfbLeVq+JceQIUMK97X1wDNnzszG1q5dm+KXXnopGxs9enSKzz777GzM17hYvq7Y1vk+9NBD2ZitcS7jr+2cc85Jsa8TBFA9thbs2WefTfHUqVMLX2Pbh0nSsGHDUuyXP7c1wI2N+arkL774YquxVJ6ffJ2bXcZzw4YN2ZitY160aFHhmG91Ztui+WPOnj07xTZ3leVNAJWLMWa55Lnnnkuxz002h23atCkbGzp0aKv7SXlumjNnTjZm505+WfZRo0al2Ocm2z7N83nE1vmWzZ38MsW2nZs/pm0Fu3HjxhSXfa6KO78AAACoG0x+AQAAUDdqUvZw8ODBrGWFLXXwt+BtO4sxY8ZkY/b2f1mbnTVr1hSO+WNa/nGdbQ8kSYMGDUqxLbOQ8kegvszBtmyzrZIkac+ePYXX9rWvfa3V4wOonoMHD2btfmy5kV8NzeanM888MxuzqyiVrUa0atWqwmvxOcCWIfhj+uPYFZ58frKPQX0rRvvey/LTuHHjsrGvfOUrKbat3OzqSgDa79ChQ9ncyZY6+FXcbG7yP6v2Z9LnEbvt5zx2fmZLsPzrfDmBz01lcyebm3yrM9vOrSw3jR07Nhv76le/muKy1S0t7vwCAACgbjD5BQAAQN1g8gsAAIC6EWqxjG7Xrl2jrfn4t3/7txT7pTatBx54INu2tS/veMc7sjFb//HZz342G7v55ptT7JdMtu3U7FLD0rG1a3aZQf99ssextX+SNHLkSBWxrY18DWGZEMLiGGPj8fcEUMbnpzvvvDPF8+bNy/a1P/f33XdfNmaXPL/qqquyMZufvvjFL2Zjf/3Xf53isvw0fPjwbMzX/PnWkNbevXtT7POTr+Wz7Ocnxo8fX7ifdd5556mpqSkcf08AZcpy0/z58wtf53OTrZ295pprsjG7TPtNN92Ujf3t3/5tistyk11qWCr/rERb5k7Vzk2NjY2FuYk7vwAAAKgbTH4BAABQN2pS9jBu3Lj4mc98Jm1/9KMfTbFdsUTKW3nYW+VS+eocy5cvT7EvH2hqakrxwoULC4/hHyP6th+TJ09OsV/ByW7btkZSXj7hv79du3YtPGZZOzfKHoDqGDt2bLzxxhvT9sc+9rEUP/PMM9m+06dPT/GuXbuysV69eqXY/+wuXbo0xb4N0eLFi1Ps25DZXGLLrqRjWzpOmTIlxf6xo807Po/aPOtzkF2pyR+zqA3bueeeS9kDUAVjx47N5k42N9k5j5S3aLRlTtKxq0FaTz/9dIp9biqbO9mfeZ8b/NzJ5iY/z7I5x7czs2UQPjfZPOZLVG1usivDUfYAAAAAiMkvAAAA6giTXwAAANSNmtT8hhA2S1pX9QPXt7ExxiGn+iKA0x35qerITUAVkJuqrjA31WTyCwAAAHRElD0AAACgbjD5BQAAQN1g8gsAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtMfgEAAFA3mPwCAACgbjD5BQAAQN1g8gsAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtdanHQAQMGxJEjR6btXbt2pXjIkCG1OOUp9cYbb2Tb3bt3L9x38eLFKZ47d27F51i8ePGWGONb75sHnGRl+Wnw4MHZviGEwuMcPny4cL9Dhw6luFOn/B6D3Y4xVnjVx7Kvtdfiz+/zU9++fQuPafPTnDlzKrqOdevWacuWLcXfKAAVGTBgQBwxYkTa3r17d4rfKnOngwcPptjnpl69ehW+rj1zp7Vr1xbmpppMfkeOHKkf//jHafuBBx5I8fXXX1+LU55Sq1atyrYnTZpUuK/9R7Kpqanic4QQ1rX9ygB4I0eO1B133JG2H3zwwRR/+MMfzvbt3Llz4XH279+fYj/53blzZ4p79uyZjfXu3bvVY0jHTpTLxuw/HHv27Ck8/4svvpiNXXbZZSn2k2/7fh9++OHCa7Gvu/DCCwv3A1C5ESNG6LbbbkvbixYtSvENN9xQlXPYX4zL8lu1+F/Mt23bluI1a9ZkY+eee27hcdozd2psbCwco+wBAAAAdaMmd367d++e3f2cOnVq1c/x+OOPp/i8886r+vHbouxOr1fpY87XX3+9vZcD4DjsHY+PfOQjKbaPGSXpzTffTPGgQYOyMXsHpWvXrtmYvTOxcOHCbMw+KZo4cWI2ZvODvUMiHXsHxZZo+MeF9lr9OdatO/oQyT5ilaQtW7ak2N8V6tLl6D8XTzzxRIr37t0rACeua9euGjZsWNqu1t1eyz6Jv+SSS7IxO+8YOHBgVc7nn1jZ3ORzqs2/9gmZVPnc6YUXXkixL6vIrquiowEAAABvAUx+AQAAUDdqUvYQQsgekT399NMpnj59eruOaT/AIZ36Uodnn302xTt27MjG5s+ff8LHr9YjBwC5Hj16ZKVKd999d4ovv/zybN9+/fql2JY5HDnOEcuWLcvGrrnmmhQfOHAgG7Pn9mP20V5ZmYWUl0H4EgX76M9/qG7GjBmtnk/K368fs3luwIABKba5HkD7denSRUOHDk3btkTh4osvbtcx/QdefamDdTLmHcuXL0/xvn37srGyD7xVyr6Hsg/0cecXAAAAdYPJLwAAAOoGk18AAADUjZNSrNXeOl+rbFWi9rr33nuz7bJaGG/atGnVvpyMb1oPoDoOHjyYtRF717veleLt27cfs+8Rvp2Yrbm1dbSStHHjxhR369YtG7Ptd0aNGpWN2dZq3/ve97IxvwCHrZfz9cCjR49Osa1NlvLPT/h6YFtn7I/Z0NCQYlurfCKr1AEo1t46X+vMM8/Mtm3+8TWxdqxstbV//dd/zbavu+66iq/nnHPOqWg/n38qXZDD5sWy3MSdXwAAANQNJr8AAACoGyel7MHehraPzk6Gslvn69evr8o57JrTUv6otL1rZ5c9cgBQPU899VSKZ82alY3Zx2Z2ZTTp2JIFy66c5tuZde/ePcW2ZaKUt0HbunVrNua3bUsfWy7ht30Osq0n/SNI+zqf1zZt2pRiW/blyyoAVMdLL72U4jFjxhTut2vXrmy7T58+hfva/OPZtoX2511StvLcK6+8UniMtvA5xh73jDPOqPg4dpXJkSNHptivvGlx5xcAAAB1g8kvAAAA6gaTXwAAANSNk1Lze7LrfJcuXZrimTNnFu73u7/7u6XH+cu//MsU33jjjdnY7/zO76S4Wq1+7HGmTp1alWMCyHXp0iVr6WVjW68vSbt3707xuHHjsjHbJswv8Wtr2XzN7YMPPpjiBQsWZGM2B3zyk5/MxjZv3pxtf+lLX0rxhz70oWzsT//0T1s9piRt2LAhxa+//no2ZlsdDR8+PBuz3xvbvtIupQygesrqfK2yGt+2ePzxx1N83nnnFe73iU98Itv2edPOnf74j/84G/vIRz6SYp+bbO2uV/bZMZuL586dm+K1a9cWHo87vwAAAKgbTH4BAABQN0ItVueZNWtW/MUvfpG2X3zxxRSff/75ha977bXXsu2hQ4emeNWqVdmYbQn08ssvZ2O2BdCf/MmfZGP33HNPilesWJGNlbVF848chwwZkmLfgsg+RvXs4wH/qLRMCGFxjLGx4hcAaNW0adPiD3/4w7RtH429973vzfZ99dVXU+xz0MSJE1O8fPnybMy2EPMtg2xrsG984xvZ2COPPJLiJ598MhvzOWjw4MGF+9ocaN+DlD/O9I8r16xZk2KbY6W8DZptIXT++eerqakp71kEoM2mT58e77zzzrRt2yteeuml2b52FVg7x5LyVd18brKloL7da+/evVNsy6ok6YEHHig8pl+R1rZq9WVRdu7kc+PkyZNVxO5r266VaWxsLMxN3PkFAABA3WjX5DeE8PTx9wIAAAA6lsLn7iGEN+GXLgAAIABJREFU9xUNSap86Q0AAACggyis+Q0hvCnpB5Ja2+H9McbC3hqNjY2xqampOlfYDmXLlbbFjh07UtyvX78TuqYTRc0vUB0zZ86MP//5z9O2XUbT1/XaJYx9XduAAQNS7JcXtp9fsDVukmTPffXVV2djdulR29qnte2NGzem2LYe8/v65UwPHz6c4m3btmVj/fv3T7FtHyRJ3bp1a/WYZXV1ACo3d+7c+Oijj6ZtW1vfls8WlSlrGXbvvfem+JJLLmnX8aXKl2UuU/YZrEqV5aayT1wtk/T1GONyPxBCuKzNVwEAAACcYmU1v38kaWfB2LU1uBYAAACgpgrv/MYYHywZa1NNw5IlS1I8Z86ctry0XWypw+c+97lsbPbs2Sm+9tryObwtdfArj9gWIf6Rp21z5K1cuTLFZW09vvCFL5ReG4D26dy5c7Yi0i9/+csUv/3tb8/2ta3A/CpKtoWYfTx55BxH2BXVpLydml850rZPu+qqq7IxW54hSTt3Hr03sWzZsmzMPiK1q7b54/bs2TMbs98Ln8fs+//KV76SYt9qEkD7hBCyXPLwww+n+IILLqj4OHa+4sueOnU6es/Tr/BoSx0+/elPZ2PTpk1LsZ872dZmUj538u3UbMsyP3eaP39+in2Zg20DefbZZ2djffv2TfHnP//5FJflptJGsyGEKyW9V9JINdf+vizp32OMPyt7HQAAANARlXV7+DtJkyXdIunIrYtRkv4ghHB1jPEPT8L1AQAAAFVTduf3mhjjMc/lQwi3S1opickvAAAATitlrc6WSfpIjPFx9/XzJH0vxji91RdKOvvss+Ptt9+etstqYNurrA2ZbTNkl0j2Qsg7YFRrqWd73Coek1ZnQBVMnjw5fvvb307bts5sy5Yt2b625nf8+PHZmK359TVvdrlRn4Pscsq+RdmuXbtSPHXq1GzM1+fZejm/VLptg+ZbDdmaP9++zW7bJZKlPK/t3r07xQsXLtSTTz5JqzPgBE2dOjX+8z//c9qeN29eim2Nv5T//Pu2Z/bn0y5ZLOX5x3+OwOYtn39s60NbYytJBw4cUKVsjvOfoyibO9ltP3cr0t5WZx+S9A8hhD46WvYwWs0dID5U0ZkBAACADqSs28MSSeeHEM5Q8wfegqQNMcZXi14DAAAAdGSl3R4kqWWy26YJb0NDQ1bqUOlqH35FoR49eqTYr7w0adKkwuOUlTrcdtttKfa31X1bjBEjRhQex66S5K+7WqUOAKrP5ye7GqVvJ2RXNVu+PF/vZ+TIkSl+/PGsOixrmebzweDBg1PsV236j//4jxRv3749G1u0aFG2bR+J+rIHWwpmyzOkfOUkWwIh5a3P/HXbR6n20aXNhQDar6GhQTNmzEjbTz75ZIptm1bPljlJeW7yq+02NhZXT9pSB7+i5I9+9KMU+zIHnxvLSl3tvM7nuLK5U6WlDra1Y9nxyha5KLuIJcffCwAAAOhY2jX5jTHWfqUKAAAAoMoqmvyGEAaGEAbU+mIAAACAWiprdTZG0tckXSppu5o/8NZX0q8kfSrGuLbooI2NjdHXmXREvt6kf//+p+hKjo9WZ0B1zJkzJ95///1p27bb8fX7ZfWstrbML29s2xD5JTxtzh02bFjh8X0dsa+js3W+/jo3b96cYt/OyL5H/36HDBmSYttOUspbJtnjX3nllVq6dCmtzoATdLLnTrb+X8rziM9p1gsvvJBt22XZj6esDZvl56aV1vzaeuT58+dr8eLFrb6w7M7v7ZLulHRGjHFSjHGipOGSfiLptpLXAQAAAB1S2eR3cIzx9hhj+tUgxngoxnibpEElrwMAAAA6pLKyh9skvS7pXyStb/nyaEm/p+aJ8QeKDtq3b994/vnnp+177rknxW/FNmDVKp+wq0n51kWUPQDV0b9//3jRRRel7bvvvjvFPj/Zx4C+LZlfVcmyx/FtgWz7tA0bNmRjthWkX33NryJnz+H3tS3LbLskSZo1a1aKfZ6xj0F9uUbR6k9lqygBqFy/fv2iXXHy5z//eYrL5k7tLREoc7z8Uw2rV6/OtidMmNCu42zatCnFtpSsvSu8/a6kD0v6go4ucrFe0n9K+l67rhAAAAA4hcpWeDsg6R9a/gAAAACnvXb1+QUAAABOR8dd3rg9Jk+erF/+8pe1OHRF1q1bl+KxY8fW/HxtqfFduXJliidPnpyN+fo7ANU3ceJE3XXXXa2O+brehoaGFPsaX1sf619n24v5+rv169en2OcnW7vna+z8MsW2Rdtrr72WjdkllP1ypnZpYt/O6JFHHknxggULsrFx48aleMuWLSm2n1UA0H6TJk3Sz372sza/rqzG19ful7Uwa+/cqexzDdu2bcvGBgw4umREW2p8bQs4n9PKWkYW4c4vAAAA6kalK7y93f4NAAAAnI4qvfP7dfc3AAAAcNppa5Fpxc3jbH/MsmU4rbLakLaoRZ3vDTfckG1/5zvfaddxfJ0vgJPrwIEDeumll9K2rTvztWu2ntUvO2r75fp6YFtXa+vfJGnUqFEp9ksI7927N8UjRozIxmwdr5TXB//VX/1VNvbVr341xatWrcrGxo8fryK2f2+nTvm9EVv/3KNHjxTzWQWgOg4dOpStGzBw4MAUl82dypYbLqvx9f2By+ZOdjn37t27Z2M+x1mf+tSnsu3vfve7KX799dezMft+vZkzZxaOtQc1vwAAAKgbTH4BAABQN2r2vMo+Miu7XW+1pczB3i73t8rXrl2bYtuep6127tyZ4vaWOQDoWDp16pQ9wretgPzjQ1siMH369GzMPk70rYaefvrpFM+ePTsbu//++1Ps24nZtom2lVpr53j55ZdTXJaffF61pR3+HEOHDk2xb2FmH21WY/lUALnOnTurX79+advOncpKBGyZw/HYJYV9qzG7FLrPW77Uocwrr7ySYlvm4JWVOXhl5RvtUemd390tf+8q3QsAAADowCqa/MYYL7Z/AwAAAKcjan4BAABQN05Kjxpbt+Lb57SXbS3k23WcSJ2v1bdv38Kx9r4nuwypra8DcHJ07tw5WxrY1r2WLbfp2/nYWmHfsmzu3LkptssZS9Lb3va2FPsli21dW+/evbMx31LM1gdv2rQpG9u3b1/hcWze8TW/Dz/8cKvvQcpbHdn3y/LGQPUU1dO3pT7W8p+5svXBe/bsycZsnW/ZksXHM3z48BT75ZXtZ6l8biqrK3722WdTPG3atML9bD7yc0OLO78AAACoG4WT3xDCxBDCha18fUEIofj2CAAAANBBlZU9/J2kT7fy9X0tY++q9CTVKnWwym5nV8o/DmjLdZbta1dosY8mpcpLHWglBNRO0c+vbydkH/X7x472MaB/fGfz04YNG7Ixu+LapEmTsjH7yG7NmjXZmG9nZFsi9ezZMxvbv39/im2JhyQtXrw4xeecc042Zh972lXcpPw9DRs2TABOnbIV1yyf6+zPsV1RUpK2bt2aYr9qpbVly5Zs268+afkWZWXHtTnPr0RZVupQdr4iZbO9cTHGZf6LMcYmSeMqOjoAAADQgZRNfnuUjDWUjAEAAAAdUtnk94kQwkf9F0MIH5a0uJX9AQAAgA6trOb3jyTdGUL4oI5OdhsldZN0bVtOsnz58hT7GrNT6URqkW2rH1873JZlmov4Whxf0wegfWKMWfsdu6TnnDlzsn1t/Zhv2WNbAfmfV7t88pAhQ7IxWytsa3P9tm+7Zmv8/LX5Nmi7dh1djNO/btasWSn2OdAex78n2xZt2bKjFXG/8Ru/IQDVt2TJkhT73FTpcsP+81H280R+XlHpPKOsxvd4tm3blmI/d/J1vu1hW0tec801hfsVTn5jjJskXRBCuETSkRnr3THGX53w1QEAAACnwHEXuYgx3ivp3pNwLQAAAEBNnZQV3mpd6rBy5cpse/LkyRW9bvfu3dm2b1dU5plnnknxBRdcUPHrKuVXXgFQHTHGrGThvPPOS7FtUyjlJQr+Z9K2EPMtDW3LtM2bN2djdgVK/+iyc+fOKV66dGk25ssg7L5+hbm1a9em+Pzzz8/G7L6+7OKMM85IsX8Eah+XVqPVJIByvtShSNlqbGVtU59//vlse8qUKRWdz+YXSRozZky2XVZSaudOF110UeF+vlyr0jIPW57GCm8AAACAmPwCAACgjjD5BQAAQN04KTW/tkWOrVOrll//9V/Ptm3rojJtqfH1NXW2zveVV17JxoYPH17xcS3bIs22AwFQPTHGrMWOrXvzyw1bfklP28LMt+yxSw9feuml2ZjNT+vWrcvGRowYkeKzzjorG7Pt06S8lu/ll1/OxubNm5fiRx99NBuzNcB+yWZbL+ePOX/+/BTbz1lUWosHoG02bdqU4rIlxX19rK35LePbFNrcZNslSvlnHOznFo7npZdeyrZtne+zzz6bjdkljMvyiv9shs3b9jMWpcs+F44AAAAAbzFMfgEAAFA3TkrZQy1KHSxf5mDbW5S1+fDKVkKxjzG99pY5eP/0T/9UleMAKHbo0KGsjMmWF/hV3OzjxLFjx2Zjtr2Qz3F2+/HHH8/GbInEqFGjsjHbIsi3C1qzZk22bcuk7CNJSXrttddS7Fsx2pIq/3h03759Kfbti/7iL/4ixbYE5ODBgwJw4g4dOpT9fJaVOlj+579SZXOnthxz69at2fagQYNS7Fe8tfnCljkcj823vrXk3/7t36Z4586dKbYltx53fgEAAFA3mPwCAACgbjD5BQAAQN0ItVimslu3bnHo0KFp+4477khx2VLAvmWYbZHhl+i0PvWpT2XbX/3qVyu+1tNFCGFxjLHxVF8HcLrr0aNHHD16dNr+0Y9+lOK5c+dm+9r8uGjRomzM1g1fdtll2djevXtT7PPRl7/85RT7dkJ2uWG71LB0bG2t3dfncTvmlz4dOXKkitjWa77Guch5552npqamyj9cAaBV3bt3j/YzRDY32VaD3vLly7Nt2+7rkksuKXzdJz/5yWz7a1/7WuG+9vMPbWlv6HOTrcP1Ldp69epVeBybb8s+g2U1NjYW5ibu/AIAAKBuMPkFAABA3ahJ2cPkyZPjt771rbR9xRVXpNg/uuvSpX3d1nbv3p1iv1Lb+vXrU2wfbx6Pb3PUtWvXdl1bLVD2AFTHmWeeGT//+c+n7d/7vd9L8XPPPZfta1vx2Jwj5Y/ofEtF+xjSlw889dRTKfaPMm0+9I8E/Wpw48ePT7FfYc5u9+jRIxuzx/Wvs/v6fGjbt9m47NEigMpNmDAh2tKD6667LsWvvvpqtq8vi6rUxo0bU+xLoJYtW5biGTNmVHxMuxKdVHmLtlqj7AEAAAAQk18AAADUESa/AAAAqBs1qfkNIWyWtO64O6ItxsYYh5zqiwBOd+SnqiM3AVVAbqq6wtxUk8kvAAAA0BFR9gAAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtMfgEAAFA3mPwCAACgbjD5BQAAQN1g8gsAAIC6weQXAAAAdYPJLwAAAOoGk18AAADUDSa/AAAAqBtMfgEAAFA3mPwCAACgbnSpxUEHDx4cx40bl7Z37NiR4n79+tXilKeNxYsXp3ju3Llted2WGOOQWlwTUE8GDhwYR44cmbb37t2b4gEDBlR8nBhj4djhw4dT3KlTfo8hhFB4jErH/Ljf157/zTffzMYaGhoKr9vmpzlz5hTuZ61bt05btmwJx98TQJlBgwbFMWPGpO1du3aluH///qfikjqM9syd1q5dW5ibajL5HTdunJqamtL2XXfdleJ3vvOdtTjlacP+A2a/RxW8bl0trgeoNyNHjtRPfvKTtG2T6nXXXZft27lz58Lj+EmltW/fvhR37949G7Pb/hh2ony8ye/BgwdTfODAgcLzv/baa9nYOeecU3gOe/7HHntMRezr5s2bV7gfgMqNGTNG9957b9r+1a9+leL3ve99p+KSOoz2zJ0aGxsLxyh7AAAAQN2oyZ1fr97v9lplj0oB1F6nTp3Uq1evtP3+978/xW+88Ua276FDh1Lcu3fvbMyWFvg7xJs3b07x6NGjs7FNmzaleOjQoYXXuWfPnmOu2+rZs2eK/d1le63+HPbaBg4cWHhOfz67/eKLL6bY33UG0D6dO3fOyhvq/W6vVe25E3d+AQAAUDeY/AIAAKBunJSyh7e6Z599NtueNm3aKboSAMfTtWtXDRs2LG0/+eSTKZ4xY0a2r+2M4B+7de3aNcUbNmzIxiZMmJBiWzohKTu3H7PnKCuz8Nu+RGH9+vUp3r9/fzY2adKkFPsP0fXo0UNF7HHstZV9KBAArG3btqXY583p06eftOvgzi8AAADqBpNfAAAA1A0mvwAAAKgb1PxWATW+wOnj8OHD2apudiUzuzjEkX2P6NatW+ExR40alW3bVS19rbBdnGLw4MGF53vggQeysYsvvjjbtgtk+MUybHsz3wbN1u761/Xp0yfFvh7Zvn/7HmjfCKBSdhXNtqyoWW3c+QUAAEDdYPILAACAukHZQxX4dkE8BgROH7YtmF+Nzf4sb926NRsre2TXt2/fFPsWZbY12MaNG7OxM844I8U+r/iSDNuGza+yZl/r26C99tprKR4yZEg2Zksd/Plti6Lhw4en2LZ8A4BKncq5E3d+AQAAUDeY/AIAAKBuMPkFAABA3XhL1vxu3749xf3796/5+WpRp/KLX/yi6scE0FwD26tXr7RtY1+fa2tpBw0alI3Zdl++rtbWsvn88Nxzz6V46tSphde5YMGCbHvPnj3Z9l133ZXi+fPnF47589v8aFu+Sfn798sr2/f0F/9/e/cao1dV73H8t3qZtjOdmV6m9EaHaeklVEQjUyBo8aABKUqO+gJvR5A0RmNCMfpCDkdNvBxizNFUCRBOrEl9oS0vLLQoHhK5GGNApiXBpA1QS0tL6Z1epu3M9LLOiw5r/ms5z+7MdO9n5pn9/SSkaz9rP/tZT5Nul3t+8///+Mdh/M477/T/BQDUlCNHjoTxtGnThnydN954I4xtO3VJ2rp1axgXsXd67LHHwvjgwYMVzxvSk1/n3C1DeR8AAAAwnIYae1iT6yoAAACAKnCVHjs75zZWeo+kj3nvGyrMq7293Xd0dOSwvPz98Y9/DOPbb799GFcyOM65zd779uFeB1DrrrnmGr9xY9/tzZYwu/baa6Nzbac2WyJMkmbOnBnG+/fvj+ZshzV7DSnuuPbss89Gc/bHhd///vejOVtqTIrLqe3bt6/iZxw/fjyamz9/fhinMQ/7HW3ZNSmOeYwb15eYW7ZsmTo6OuKaRQAGbSTtnV566aXo+MUXXwzj++67r9rLGZL29vaK96aszO9ySf8hqTN53Um6Lqe1AQAAAFWTtfl9UdIp7/0L6YRz7rXilgQAAAAUo+Lm13u/ImPupmKWAwAAABRnQKXOnHPTJHnv/bsXPXmEq6WcL4D8jRs3Lipb1tbWFsZ79+6NzrXnzZ07N5qz7YXtWIrLiaXv+8c//hHGd955ZzRnWx/bjK0kTZw4MTres2dPGF9xxRXRnH1vWqLN/p5HV1dXNGezymfOnKm4trQtKYDR5frrr888rnUVqz0451qdc+uccwclvSTpZefcgd7X2qq1QAAAACAvWaXO1kvaIGmW936R936hpNmSnpC0rhqLAwAAAPKUFXto8d6vty94789JWuec+9FgPuTEiRNh3NjYOKgFAkCenHNRhODVV18N46uvvjo699y5c2Fsy3tJ8X0t7fBmIwJpibIPfvCDYWxLrklx+bSlS5dGc+m903ZgS+MaNnaRxhc+8IEPhHFdXV00Z7vPpXEN+3f25z//OYzTUm4A8pFXx7WhsPcCKbsb5UhiY2WnT5+ueF7W5nezc+4RSWsl7e59bZ6kuyW9culLBAAAAKora/N7l6SVkn4gaa4u1PfdI2mj6PAGAACAGpRV6qxH0qO9/wEAAAA1L7PUmXPuE5I+rQtPfr2kvZKe9N7/aTAfMlJzvg8++GB0/MADD+Ry3RtuuCGMbUtAAMOvq6tLr73W16dnyZIlYZzmc23md8aMGdGcLRmWlQdOy6Bt3749jG+99dZorqenJ4y/+93vRnOrV6+Ojpubm8M4zRzbz5w6dWo0d9NNfWXa0/bKCxYsqLjuStew2WMA+al2ztfKyvjee++90fFDDz2Uy2dec801YWx/F2Mw3v/+94dx1j2s4ubXObda0mJJv9GFuIMkXS5plXNuhfe+Npo7AwAAAL2ynvze7r1fnL7onFsv6XVJbH4BAABQU7I2v13Oueu8939PXl8mqau/N9SavGIOKaIOwMg1YcKEqKvbjh07wnjx4vj/79uSZfv374/mmpqawthGGSTpfe97XxjbeIQUxwQ6Ozujua1bt4bxL37xi2hu586d0bHt6pZ2XBs/fnwYp1GOF154oeL7bHwjXXd3d3cY2zgIgHLJK+aQGmrUYSiyNr9fkfSoc65RfbGHeZKO984BAAAANSWr2sMWSdc752bJlDrz3u+r1uIAAACAPGVWe5Ck3s0uG14AAADUvItufvvjnNvivf9Q3osBgKI556Jsqy3pk7YCttnWtGSYnUuzwratZpqPtcdTpkyJ5m688cYwTjO+c+bMiY7Pnz8fxmk+134Pm02W4nJq6fe1eWSb8ZUuZKX7e1+aGwaAkW7MxU/5V2x8AQAAUIsGtPl1zk1zzk29+JkAAADAyJXV5KJV0k8lfVzS0QsvuSZJz0q633u/s9J7u7u7o/JBN998cxjv2rXrkhcNAEN18OBB/epXvwrHDz/8cBhv27YtOtfGCdKyZFmdzWyswsYTpLh82uHDh6M529EpjTnU1dVVXNvJkyejOdv9bffu3dHcvHnzwthGGdK1pl3r9u3r+9WP2bNnh3HaXQ7A0Bw9elRPPvlkOP76178exu+8885wLGnUyrprrZe0QdIs7/0i7/1CSbMlPSFpXTUWBwAAAOQpa/Pb4r1f770Pv53hvT/nvV8naXrxSwMAAADylVXtYbNz7hFJayW993OzeZLulvRK0QsDAAAA8ubSEjlhwrk6SSsl/bv6mlzslrRJ0hrvfXe/b5TU3t7uOzo68l/tAHV19XVfnjhx4rCtI0/Ouc3e+/bhXgdQ67LuT2l21uZs0wysvXeeOnUqmssqGWbLoKWlzuw10xJiaebYtjA+ceJExc9P74F2PTZ/LMW/kzF//vxozuaB7TWWL1+uLVu2UO8MuETDvXc6evRoGKf3plrU3t6ujo6Ofu9NWR3eeiQ92vsfAAAAUPP4NV0AAACUBptfAAAAlMaQ2hsP1v333x/GP/nJTwr/vCJyvmmL0jQrB6A2nD17VgcOHAjHX/va18J4w4YN0bn2331ao9zWy500aVI0Z3/vIK3Pa7O6Nv8rxa2Hba1eSaqvr1clGzdujI4///nPh7H9rpLU0tISxmmueMaMGRXnbObZ3v+o8wsU44tf/GIY//a3vy3884rI+T733HPRse37MJwG2uHtY/ZPAAAAoBYN9P+y/0/yJwAAAFBzBht7GFI5m2pEHYpGzAEYHcaMGaOGhoZwbKMOaUTgsssuC+O5c+dGc1n3BNtSuK2tLZp7/fXXw3jRokXRnI1PpG2RUzZacc8991Q8L41LnD17tuJnNDY2Vpyz3zeNRADIXzWiDkUbKTGHFGEtAAAAlAabXwAAAJQGm18AAACUxkAzv+/11TyReVYFtlxQXtnZX/7yl2G8atWqXK4JYPRzzkXlxmx5MZvxTaXtje19LS1Z9sMf/jCMf/7zn0dzixcvDuO0LbG9P06YMCGaS0uK2dxteh27nnTd06dPD+M017tjx44wbm1tjeZs62V7/YtlkwEMTVa786H69re/HcY/+9nPcrlmLRrQk1/v/U32TwAAAKAWEXsAAABAaVSlw1sRZcJGe9Thc5/73HAvARi17I8TbQe2kydPRuedOXMmjCdPnhzN2RhC2lXy17/+dRgfPXo0mtu/f38Yz5w5M5qzEYJDhw5Fc7b7mhSXRUsjEvY4nbOd6i6//PJoznatS+MS1p133hnG//znPyueB2DoiigpONqjDitWrAjjN954o+J5PPkFAABAaVTc/DrnFjrnPtzP68udc1cWuywAAAAgf1lPfler/+oOp3vnAAAAgJqSlflt896/mr7ove9wzrUVtqIadPz48ei4qanpkq+5fv366Pjxxx+/5GsCuMDmdQ8ePBjGLS0t0Xm2DbItbZYenzp1Kpprbm4O4zQrPGXKlDC2mWIpbj2cZnzTz7ffIS2DduzYsTBOc4O2hFk6Z6+Trs1+/po1a8LYZuwAIEvWfdO2Vx+qp59+Oozb29srnpf15HdixtykjDkAAABgRMra/L7snPtq+qJzbqWkzcUtCQAAAChGVuzhm5I2OOe+pL7NbrukOkmfKXphtSSPmAOA6vDeRz/St13d0h/D2XJfthOcFJcQS+8BtmRad3d3NFdfXx/GaYk0GzvYs2dPNJfGIGyXurRE27vvvhvGixYtiubsd7QxCyn+HrYEXMqWYbNl4wAgiy31OGfOnGFbR8XNr/d+v6QbnXM3S7q69+U/eO+frcrKAAAAgJxdtMmF9/45Sc9VYS0AAABAoWhyAQAAgNKoSnvjor399tvR8dy5c4dpJZfmjjvuCONNmzYN40qA0c3mVPft2xfGabthe15nZ2c0Z0uYpblX23r4sccei+a+9a1vhfHhw4ejOVsGbdasWdGczfim0ussWbIkjHfs2BHNzZ8/P4zTUme2vXLalvkb3/hGGK9du3ZA6wIwcv3ud7+Ljr/whS8U/plF5Hw/9alPhfFTTz01oPfw5BcAAAClweYXAAAApTEqYg+1GnNIEXUAinf+/Pmo/JiNF6Rd1GwpsGnTpkVz9tysTmn33ntvNGc/O72mvU7atS2NNtgyabZ8miSdONHXmX7BggXRnC11Zku5SfH3tREMSVq1alW/108UL6KjAAAOuElEQVT/zgDUhmrEHKphoFEHiye/AAAAKA02vwAAACgNNr8AAAAojUIyvzt37tTKlSvD8Zo1a4r4mOCvf/1rdPyRj3yk0M8DULvefvttfec73wnH3/ve98K4tbU1Otfmbrdv3x7N2XbHixcvjua6urrC+PHHH4/mvvzlL4dx2k7Ztl1ubm6O5qZOnVrxXNtqWYpLr9lWxJI0ffp0VXL8+PEwtuXaJOmGG27o9z1pbhjA0OzcuVP33HNPOH7wwQfDePbs2bl/3u9///vo+LOf/WzunzFS8eQXAAAApcHmFwAAAKXh0s5EeWhvb/cdHR25X7fMnHObvfftw70OoNZdddVV3nYoW7ZsWRjbbm9SXAbNxgwkqa6uruJnvPXWW/1eQ5J27doVxldeeWU0Z2MWaQmxI0eORMcNDQ1hnBV7yCpnlt7/7bm225tUuQxbe3u7Ojo64lpvAAaNvVO+su5NPPkFAABAabD5BQAAQGmw+QUAAEBpFJL5dc4dlLTroidiMK7w3s8Y7kUAtY77U+64NwE54N6Uu4r3pkI2vwAAAMBIROwBAAAApcHmFwAAAKXB5hcAAAClweYXAAAApcHmFwAAAKXB5hcAAAClweYXAAAApcHmFwAAAKXB5hcAAAClweYXAAAApcHmFwAAAKXB5hcAAAClweYXAAAApcHmFwAAAKXB5hcAAAClMa6Ii7a0tPi2trZwfO7cuTAeO3ZsER856m3evPmQ937GcK8DqHXTp0/3ra2t4birqyuMGxoacvkM730YO+dyueZQP//8+fPRXNY9+NixY2Hc3Nw8oM/auXOnDh06VP0vCYwy6d6pu7s7jCdMmDAMK6ptWfemQja/bW1t6ujoCMdDuaEi5pzbNdxrAEaD1tZWPf/88+H4tddeC+PrrrtuwNexG8zU2bNnw3jcuPg2azfD6TUGOifFm9r0XPv59n9AJampqaniup966qkw/uQnPzmgtS1btqzi9QAMXLp32r59exgvXLhwOJZU09rb2yvOEXsAAABAaRTy5DfF014AI8WYMWM0ceLEcGyf9qYRAfuEM40LZEUb7NPe9KlsT09PGGf9KNPGxfr7/DFjKj+7sOemn2GfBNfV1UVz9mlvVlzj5MmTYZz+nQHIB097i8OTXwAAAJQGm18AAACURlViD6PdxX4xBcDI4ZyLogDHjx8P46xfBkvZ2MHp06ejuUmTJlV8n/3srF+aS39RbjBOnDgRxqdOnYrmZs6cOaRr2niDjY1wvwMwFDY+JeVXbWcgePILAACA0mDzCwAAgNJg8wsAAIDSIPObAzJvQG2x+VWb803Ldtl/21n/zm0GVorLlKUly+xxVjbYNgeSsktGpuu2121sbKx4bpo5tiXS0jmbcU6/EwAMVjUzvime/AIAAKA02PwCAACgNIg9ACg1W6YsK4Zw5syZ6Hj8+PFhnEYibHwg7cRmu6p1dXVFczY+kXZmyyqpmM7ZMmmbNm2K5mwXt7RrXBbbGc6ujdgXgFrDk18AAACUBptfAAAAlMaQNr/Ouf/NeyEAAABA0Spmfp1z0ypNSbq9mOUAQPFsDjcr52uztDbjOxhpGTLbenjKlCkV35eWT0tzvYcOHap4nSNHjoTxHXfcEc3ZMmVZ7ZXTLK/NEb/55pthbLPAAFALsn7h7aCkXbqw2X2P7z2+rMhFAQAAAEXI2vzukPRx7/1b6YRzbndxSwIAAACKkbX5XS1pqqR/2fxK+mkxywGAYp0/f14nT54Mx2fPng3jtIuajSykpc5syTJ7DSkuIdbT0xPN2a5GBw4ciOY6OzvDeMGCBdFcep1p0/qSaWl8wXatO3XqVDRXX1+vSuxn2O8nxVGR+fPnh3Fakg0ARrqKm1/v/cMZcw8VsxwAAACgOJlNLpxzzZJukzRXF/K+eyX9n/f+aBXWBgAAAOSqYqkz59xdkrZI+jdJ9ZIaJN0saXPvHAAAAFBTsp78/peka9OnvM65qZJekvSbIhcGAEUYM2ZMVEbM5nPTdsM295pmW20psLQMms3OpqXUbK73ssviwjnpsZV+hm3LbHPEKVuiLJVmhdOcr0UbYwCjRVaTC6cLUYfUecXlzwAAAICakPXk978lbXHOPSPpvdJmrZJukfSjohcGAAAA5C2r2sNa59xGSZ/QhV94c5Kel/Sf3vt3q7M8AMifjTrYbmi2fJgUxwLSH/unndssWxbMdlSTpMmTJ4ex7dImxRGJtCSZvaYUxzDSMmg2EpGuc+rUqWGcfidbAi7tMGc///Dhw2GclnkDgJEus9pD7yZ3XW+rY8+mFwAAALUsq9pDq3NunXPugC78gtvLzrkDva+1VWuBAAAAQF6yfuFtvaQNkmZ77xd57xdKmi3pCUnrqrE4AAAAIE9ZsYcW7/16+4L3/pwuxCD4hTcANencuXM6duxYOLYZ2DS/avOyaRkwmwdO87g2U5xmbm2pszRjbG3bti06Xrp0aXScVcLMric974UXXgjjj370o9GczRlnlTZrbGwMY/tdAaAWZG1+NzvnHpG0Vn3VHuZJulvSK0UvDAAAAMhb1ub3LkkrJf1AfdUe9kjaKGlN8UsDAAAA8pVV6qxH0qO9/wHAqDB27Fg1NTWFY1vey5YhS6WRCBstsDEKSZoyZUq/56WfkV6zu7s7jNOYw5kzZ6LjtONbJfaa0r9GHaysqIONbxB1AFDLMkudOec+IenTuvDk10vaK+lJ7/2fqrA2AAAAIFcVN7/OudWSFkv6jS7EHSTpckmrnHMrvPf3VWF9AAAAQG6ynvze7r1fnL7onFsv6XVJbH4BAABQU7I2v13Oueu8939PXl8mqavANQFA1dgMri1flsrKuTY3N0fHtqVxWurMHtsWxVJclizN6qal1qx03VmfYc9N12a/Y3rNNLv8nqycMACMRFmb369IetQ516i+2MM8Scd75wAAAICaklXtYYuk651zs2RKnXnv91VrcQAAAECeMqs9SFLvZpcNL4BRoaenR7t37w7HW7duDePbbrut4vvSsmRZHdZsfCCNC9iYQE9PTzRnow1pXCFLeh373tOnT0dzkyZN6nedF2OvY68BALWm/xDXRTjntuS9EAAAAKBoQ9r8eu8/lPdCAAAAgKINaPPrnJvmnJta9GIAAACAImU1uWiV9FNJH5d09MJLrknSs5Lu997vrMoKASBHdXV1am1tDcd2nJb+svncrIxv+j6b87Vlz6Q4Z5tVviyVlh6zx2mu2M6l+dyscm62hXK6Nnud9DsBQC3JevK7XtIGSbO894u89wslzZb0hKR11VgcAAAAkKeszW+L93699z78X3zv/Tnv/TpJ04tfGgAAAJCvrFJnm51zj0haK+m9ukDzJN0t6ZWiFwYAAADkLWvze5eklZJ+oL4mF7slbZK0pvilAUD+vPfq6urr0P6Xv/wljG+99daK70vbDdtaumnm1maA0/a/9jjNCts8blqDN+s6Bw8ejOZaWlrCOM3nZuWMK7UwTg2mPjCAobH/dvk3l6+sDm89kh7t/Q8AAACoeUOq8wsAAADUoou2NwaA0cQ5F/3o30Yd8mo3bFsBNzQ0VJy7lDbB9keiM2fOrHhe+uPSrFJnWeXcAFQXUYfi8OQXAAAApTHQDm8fs38CAAAAtWigT37/J/kTAAAAqDmDDXi5i58CACObzb3anO9Q2w2nJcvefPPNMF66dGk0l9Um2JYaS0ubpez82bNnoznbpjjN+NbX11e8ps0jT5w4seLn0d4YQC0j8wsAAIDSYPMLAACA0qCuDYBS8d5HP7a3UYc0vmCP0zJgNgaQliS6+uqrwziNJNiYRRotqHReuk4pjkikndmy5rJKrQ209NrTTz8dxseOHRvQewCgaLbbZXrvtQb65Lez988TQ18SAAAAMLwGtPn13t9k/wQAAABqEZlfAAAAlAaZ3xx0d3dHx4NpgwqgupxzGj9+fDi2ud6s7GzKlhDr6uqK5mx2Ns0D2+xwVqvhwZRdS9n12IyvJE2fPn1A10jzz3att9xySxg3NTUNZYkASu5iv9cwFDNmzAjjrHbtPPkFAABAaVTc/DrnFjrnPtzP68udc1cWuywAAAAgf1mxh9WSHujn9dO9c3cUsqIaRMwBqC32R/g22pDVcS2NKNhSZ2nJMltiJ+3UZq+T/ljOzqVxKhvVuNi67eenMQd7bvqd7HqyIh9ZJYQAYCDyiDkMVVbsoc17/2r6ove+Q1JbYSsCAAAACpK1+a1cfV0aWCV0AAAAYATJ2vy+7Jz7avqic26lpM3FLQkAAAAoRlbm95uSNjjnvqS+zW67pDpJnyl6YQBQBO99VMZroO2G05xrmsG1bHZ279690dycOXPCOM312gzcYH6XIC1nZsuPnTp1Kpqrr68f0DXT7/vMM8+E8YoVK8I4zTQDQDVt27YtjK+66qoBvafi5td7v1/Sjc65myW916j+D977Zy9hjQAAAMCwuWiTC+/9c5Keq8JaAAAAgELR4Q1AqTjnKpYpy+q4lhVzyDJz5szouLOzM4wnT5484Ouk5cystGSQjXWkMQd7nbScmf17ScuwLV++PIxtJCLr7wxA7bARsOEsQzZYA406WHR4AwAAQGmw+QUAAEBpsPkFAABAaZD5BVAqnZ2d+tvf/haO29vbw3jSpMr9e7q6uqLjgeZqt2/fHs0tWbKk3/PSa6YZ47Fjx0bHNmub5m4rlXKTssu5ZWX+Ghsb+30Ppc6A/Nh7Qvpvvmi1lPO9VDz5BQAAQGmw+QUAAEBpEHsAUCr19fW69tprw7GNOqTRBhsRyIoLpGzHNRtzkKSTJ0+GcUNDQzSX9WPOM2fORMc22pDVDS4tWZZVmqxMP/YERqJqRx3Kiie/AAAAKA02vwAAACgNNr8AAAAoDVdEa0rn3EFJu3K/cLld4b2fMdyLAGod96fccW8CcsC9KXcV702FbH4BAACAkYjYAwAAAEqDzS8AAABKg80vAAAASoPNLwAAAEqDzS8AAABKg80vAAAASoPNLwAAAEqDzS8AAABKg80vAAAASuP/AX+K2DfVQtJWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x648 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "l1_ratio = 0.5  # L1 weight in the Elastic-Net regularization\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 9))\n",
    "\n",
    "# Set regularization parameter\n",
    "for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01, 0.001, 0.0001), axes)):\n",
    "    \n",
    "    LR_L1 = LogisticRegression(C=C, penalty='l1', solver='saga', multi_class='multinomial')\n",
    "    LR_L2 = LogisticRegression(C=C, penalty='l2', solver='saga', multi_class='multinomial')\n",
    "    LR_en = LogisticRegression(C=C, penalty='elasticnet', solver='saga', multi_class='multinomial', l1_ratio=l1_ratio)\n",
    "    \n",
    "    LR_L1.fit(X_train, y_train)\n",
    "    LR_L2.fit(X_train, y_train)\n",
    "    LR_en.fit(X_train, y_train)\n",
    "    \n",
    "    coef_l1_LR = LR_L1.coef_.ravel()\n",
    "    coef_l2_LR = LR_L2.coef_.ravel()\n",
    "    coef_en_LR = LR_en.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "    sparsity_en_LR = np.mean(coef_en_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.4f\" % C)\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L1 penalty:\", sparsity_l1_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L2 penalty:\", sparsity_l2_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with Elastic-Net penalty:\", sparsity_en_LR))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L1 penalty:\", LR_L1.score(X_train, y_train)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L2 penalty:\", LR_L2.score(X_train, y_train)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with Elastic-Net penalty:\", LR_en.score(X_train, y_train)), '\\n')\n",
    "    \n",
    "    LR_L1_predictions = LR_L1.predict(X_test)\n",
    "    LR_L2_predictions = LR_L2.predict(X_test)\n",
    "    LR_en_predictions = LR_en.predict(X_test)\n",
    "    \n",
    "    print(\"The accuracy of penalty = L1 and C =\", C,\"is\", \n",
    "          '{:.2%}'.format(accuracy_score(y_test, LR_L1_predictions)), '\\n')\n",
    "    print(\"The log loss of Logistic Regression prediction is\", \n",
    "          '{:.2}'.format(log_loss(y_test, LR_L1.predict_proba(X_test))), '\\n')\n",
    "    print(classification_report(y_test, LR_L1_predictions), '\\n')\n",
    "    \n",
    "    print(\"The accuracy of penalty = L2 and C =\", C,\" is\", \n",
    "          '{:.2%}'.format(accuracy_score(y_test, LR_L2_predictions)), '\\n')\n",
    "    print(\"The log loss of Logistic Regression prediction is\", \n",
    "          '{:.2}'.format(log_loss(y_test, LR_L2.predict_proba(X_test))), '\\n')        \n",
    "    print(classification_report(y_test, LR_L2_predictions), '\\n')\n",
    "    \n",
    "    print(\"The accuracy of Elastic-Net and C =\", C,\" is\", \n",
    "          '{:.2%}'.format(accuracy_score(y_test, LR_en_predictions)), '\\n')\n",
    "    print(\"The log loss of Logistic Regression prediction is\", \n",
    "          '{:.2}'.format(log_loss(y_test, LR_en.predict_proba(X_test))), '\\n')\n",
    "    print(classification_report(y_test, LR_en_predictions), '\\n')   \n",
    "    \n",
    "    if i == 0:\n",
    "        axes_row[0].set_title(\"L1 penalty\")\n",
    "        axes_row[1].set_title(\"L2 penalty\")\n",
    "        axes_row[2].set_title(\"Elastic-Net\\nl1_ratio = %s\" % l1_ratio)\n",
    "\n",
    "    for ax, coefs in zip(axes_row, [coef_l1_LR, coef_l2_LR, coef_en_LR]):\n",
    "        ax.imshow(np.abs(coefs.reshape((24, 24))), \n",
    "                  interpolation='nearest',\n",
    "                  cmap='binary', vmax=1, vmin=0)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "    axes_row[0].set_ylabel('C = %s' % C)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search Cross Validation to select best params\n",
    "#### Logistic (Lasso) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cvalues = [float(x) for x in [1, .1, .01, .001, .0001]]\n",
    "lr1CV = LogisticRegressionCV(Cs = cvalues, penalty = 'l1', solver = 'saga', multi_class = 'multinomial')\n",
    "lr1CV = lr1CV.fit(X_train, y_train)\n",
    "lr1CV_predictions = lr1CV.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Logistic (Lasso) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression L1 CV prediction is 88.63%\n",
      "The best Lambda for each class is [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Logistic Regression L1 CV prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, lr1CV_predictions)))\n",
    "print(\"The best Lambda for each class is\", lr1CV.C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_cleaned</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumItems</td>\n",
       "      <td>-0.570946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PHARMACY OTC</td>\n",
       "      <td>-0.422686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>-0.363963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>-0.281852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>-0.277289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekday</td>\n",
       "      <td>0.134844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LARGE HOUSEHOLD GOODS</td>\n",
       "      <td>0.198369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>0.57716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>2.96601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         features_cleaned importance_score\n",
       "1                NumItems        -0.570946\n",
       "49           PHARMACY OTC        -0.422686\n",
       "17            DSD GROCERY        -0.363963\n",
       "47          PERSONAL CARE        -0.281852\n",
       "54                PRODUCE        -0.277289\n",
       "..                    ...              ...\n",
       "63               WIRELESS                0\n",
       "0                 Weekday         0.134844\n",
       "37  LARGE HOUSEHOLD GOODS         0.198369\n",
       "31    IMPULSE MERCHANDISE          0.57716\n",
       "20     FINANCIAL SERVICES          2.96601\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = lr1CV.coef_[0]\n",
    "importance_score = []\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    importance_score.append(v)\n",
    "    \n",
    "importance_table = pd.DataFrame([features_cleaned, importance_score]).T\n",
    "importance_table.columns = ['features_cleaned', 'importance_score']\n",
    "importance_table = importance_table.sort_values('importance_score')\n",
    "importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Logistic Regression prediction is 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Logistic Regression prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, lr1CV.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on Logistic (Lasso) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>727</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>607</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>401</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>336</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>531</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>488</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          727    1    0    1    0    0    1    0    0\n",
       "5            1  607    6    2    1    5   20    6    5\n",
       "24           5   16  401   13    1   11   16   12   10\n",
       "25           1   15    3  700    4    7   15   12    8\n",
       "32           2    2    5    7  336   12   10    1   13\n",
       "35           0    7    4    3    1  321    5   15   37\n",
       "36           3   37   11   13    5    5  531    6    9\n",
       "37           1    6   11    2    2   11    6  488   30\n",
       "38           2    9    8    4    3   39   15   32  504"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = lr1CV_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Logistic (Lasso) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.98      1.00      0.99       730\n",
      "           5       0.87      0.93      0.90       653\n",
      "          24       0.89      0.83      0.86       485\n",
      "          25       0.94      0.92      0.93       765\n",
      "          32       0.95      0.87      0.91       388\n",
      "          35       0.78      0.82      0.80       393\n",
      "          36       0.86      0.86      0.86       620\n",
      "          37       0.85      0.88      0.86       557\n",
      "          38       0.82      0.82      0.82       616\n",
      "\n",
      "    accuracy                           0.89      5207\n",
      "   macro avg       0.88      0.88      0.88      5207\n",
      "weighted avg       0.89      0.89      0.89      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr1CV_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic (Ridge) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cvalues = [float(x) for x in [1, .1, .01, .001, .0001]]\n",
    "lr2CV = LogisticRegressionCV(Cs = cvalues, penalty = 'l2', solver = 'lbfgs', multi_class = 'multinomial')\n",
    "lr2CV = lr2CV.fit(X_train, y_train)\n",
    "lr2CV_predictions = lr2CV.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Logistic (Ridge) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression L2 CV prediction is 89.28%\n",
      "The best Lambda for each class is [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Logistic Regression L2 CV prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, lr2CV_predictions)))\n",
    "print(\"The best Lambda for each class is\", lr2CV.C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_cleaned</th>\n",
       "      <th>importance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COOK AND DINE</td>\n",
       "      <td>-2.12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumItems</td>\n",
       "      <td>-1.56491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>INFANT CONSUMABLE HARDLINES</td>\n",
       "      <td>-1.44819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HOME DECOR</td>\n",
       "      <td>-1.28486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>-1.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MEDIA AND GAMING</td>\n",
       "      <td>0.439256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HARDWARE</td>\n",
       "      <td>0.48443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>1.52173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LARGE HOUSEHOLD GOODS</td>\n",
       "      <td>3.77558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>6.54997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               features_cleaned importance_score\n",
       "15                COOK AND DINE         -2.12744\n",
       "1                      NumItems         -1.56491\n",
       "33  INFANT CONSUMABLE HARDLINES         -1.44819\n",
       "26                   HOME DECOR         -1.28486\n",
       "54                      PRODUCE           -1.073\n",
       "..                          ...              ...\n",
       "41             MEDIA AND GAMING         0.439256\n",
       "25                     HARDWARE          0.48443\n",
       "31          IMPULSE MERCHANDISE          1.52173\n",
       "37        LARGE HOUSEHOLD GOODS          3.77558\n",
       "20           FINANCIAL SERVICES          6.54997\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = lr2CV.coef_[0]\n",
    "importance_score = []\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    importance_score.append(v)\n",
    "    \n",
    "importance_table = pd.DataFrame([features_cleaned, importance_score]).T\n",
    "importance_table.columns = ['features_cleaned', 'importance_score']\n",
    "importance_table = importance_table.sort_values('importance_score')\n",
    "importance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Logistic Regression prediction is 0.42\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Logistic Regression prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, lr2CV.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on Logistic (Ridge) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>607</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>425</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>337</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>322</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>522</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>490</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          727    0    1    1    1    0    0    0    0\n",
       "5            1  607    5    1    1    5   22    6    5\n",
       "24           3   10  425   10    1    7   12    7   10\n",
       "25           3    8    1  722    3    4    6   11    7\n",
       "32           1    4    3    7  337    9   10    2   15\n",
       "35           0    8    3    4    2  322    6   14   34\n",
       "36           5   38   12   16    6    6  522    6    9\n",
       "37           1    6    9    2    2   13    4  490   30\n",
       "38           2    9   10    4    3   44   15   32  497"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = lr2CV_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Logistic (Ridge) Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.98      1.00      0.99       730\n",
      "           5       0.87      0.93      0.90       653\n",
      "          24       0.89      0.83      0.86       485\n",
      "          25       0.94      0.92      0.93       765\n",
      "          32       0.95      0.87      0.91       388\n",
      "          35       0.78      0.82      0.80       393\n",
      "          36       0.86      0.86      0.86       620\n",
      "          37       0.85      0.88      0.86       557\n",
      "          38       0.82      0.82      0.82       616\n",
      "\n",
      "    accuracy                           0.89      5207\n",
      "   macro avg       0.88      0.88      0.88      5207\n",
      "weighted avg       0.89      0.89      0.89      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr1CV_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb = nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes prediction is 53.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Naive Bayes prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, nb_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Naive Bayes prediction is 1.1e+01\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Naive Bayes prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, nb.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>673</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>187</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>338</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>38</td>\n",
       "      <td>504</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>211</td>\n",
       "      <td>115</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>341</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>185</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>385</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          673    0    4    1    5   40    2    2    3\n",
       "5          187  196   10    4    4  216   18   10    8\n",
       "24          19    7  338    7    3   61   34    9    7\n",
       "25           6   88   38  504   27   38   27   15   22\n",
       "32           1    1   14    8  211  115   12    5   21\n",
       "35          16    2    2    3    8  341    6    2   13\n",
       "36          12  185   27   20   12  150  168    6   40\n",
       "37           0    3   11    6    3  265    2  163  104\n",
       "38           1    4   11    6    6  385    2   11  190"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = nb_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.74      0.92      0.82       730\n",
      "           5       0.40      0.30      0.34       653\n",
      "          24       0.74      0.70      0.72       485\n",
      "          25       0.90      0.66      0.76       765\n",
      "          32       0.76      0.54      0.63       388\n",
      "          35       0.21      0.87      0.34       393\n",
      "          36       0.62      0.27      0.38       620\n",
      "          37       0.73      0.29      0.42       557\n",
      "          38       0.47      0.31      0.37       616\n",
      "\n",
      "    accuracy                           0.53      5207\n",
      "   macro avg       0.62      0.54      0.53      5207\n",
      "weighted avg       0.63      0.53      0.54      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt_predictions = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Decision Tree prediction is 83.08%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Decision Tree prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, dt_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Decision Tree prediction is 5.7\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Decision Tree prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, dt.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>386</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>652</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>323</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>277</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>479</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>452</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          724    1    1    0    0    1    3    0    0\n",
       "5            2  576    9    4    2    6   33    6   15\n",
       "24           2    8  386   16    2   10   21   16   24\n",
       "25           2   12   22  652   11   16   23   14   13\n",
       "32           1    3    9   12  323    8   15    8    9\n",
       "35           0   14    6   10    3  277    8   26   49\n",
       "36           0   45   15   28   16    9  479    8   20\n",
       "37           0    8   13    2    7   23    5  452   47\n",
       "38           1   11   17    9    7   53   14   47  457"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = dt_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.99      0.99      0.99       730\n",
      "           5       0.85      0.88      0.87       653\n",
      "          24       0.81      0.80      0.80       485\n",
      "          25       0.89      0.85      0.87       765\n",
      "          32       0.87      0.83      0.85       388\n",
      "          35       0.69      0.70      0.70       393\n",
      "          36       0.80      0.77      0.78       620\n",
      "          37       0.78      0.81      0.80       557\n",
      "          38       0.72      0.74      0.73       616\n",
      "\n",
      "    accuracy                           0.83      5207\n",
      "   macro avg       0.82      0.82      0.82      5207\n",
      "weighted avg       0.83      0.83      0.83      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 9, criterion = 'entropy')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest prediction is 85.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of Random Forest prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, rf_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of Random Forest prediction is 1.2\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of Random Forest prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, rf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>586</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>681</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>342</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>301</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>505</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>476</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          723    1    3    0    1    0    1    0    1\n",
       "5            2  586    9    3    2    5   31    8    7\n",
       "24           2   13  393   18    4    7   23   15   10\n",
       "25           1   11   10  681    8   12   14   15   13\n",
       "32           1    2    2    9  342    7   13    4    8\n",
       "35           0   14    5    5    3  301    7   24   34\n",
       "36           0   36   19   21   10    9  505    6   14\n",
       "37           1    5    9    4    6    7   13  476   36\n",
       "38           1   13   10    5    9   47   17   52  462"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = rf_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.99      0.99      0.99       730\n",
      "           5       0.86      0.90      0.88       653\n",
      "          24       0.85      0.81      0.83       485\n",
      "          25       0.91      0.89      0.90       765\n",
      "          32       0.89      0.88      0.88       388\n",
      "          35       0.76      0.77      0.76       393\n",
      "          36       0.81      0.81      0.81       620\n",
      "          37       0.79      0.85      0.82       557\n",
      "          38       0.79      0.75      0.77       616\n",
      "\n",
      "    accuracy                           0.86      5207\n",
      "   macro avg       0.85      0.85      0.85      5207\n",
      "weighted avg       0.86      0.86      0.86      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sv = svm.SVC(C = 1, probability = True, decision_function_shape = 'ovr')\n",
    "sv = sv.fit(X_train, y_train)\n",
    "sv_predictions = sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM prediction is 88.34%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of SVM prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, sv_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of SVM prediction is 0.38\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of SVM prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, sv.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>598</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>397</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>693</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>323</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>533</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>488</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          722    1    1    1    1    0    2    2    0\n",
       "5            1  598    4    1    2    5   23   11    8\n",
       "24           6   14  397   11    2   12   18   14   11\n",
       "25           0   11    5  693    4   11   17   14   10\n",
       "32           0    2    5    4  337   10   13    4   13\n",
       "35           0    6    5    3    2  323    7   15   32\n",
       "36           3   34    8   10    6    6  533    6   14\n",
       "37           0    8    7    0    3   10    3  488   38\n",
       "38           0   11    3    3    3   39   15   33  509"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = sv_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.99      0.99      0.99       730\n",
      "           5       0.87      0.92      0.89       653\n",
      "          24       0.91      0.82      0.86       485\n",
      "          25       0.95      0.91      0.93       765\n",
      "          32       0.94      0.87      0.90       388\n",
      "          35       0.78      0.82      0.80       393\n",
      "          36       0.84      0.86      0.85       620\n",
      "          37       0.83      0.88      0.85       557\n",
      "          38       0.80      0.83      0.81       616\n",
      "\n",
      "    accuracy                           0.88      5207\n",
      "   macro avg       0.88      0.88      0.88      5207\n",
      "weighted avg       0.89      0.88      0.88      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, sv_predictions), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning - K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn = knn.fit(X_train, y_train)\n",
    "knn_predictions =  knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of KNN prediction is 84.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of KNN prediction is\", \n",
    "      '{:.2%}'.format(accuracy_score(y_test, knn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss of kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of kNN prediction is 1.6\n"
     ]
    }
   ],
   "source": [
    "print(\"The log loss of kNN prediction is\", \n",
    "      '{:.2}'.format(log_loss(y_test, knn.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>32</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>362</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>636</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>309</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>326</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>520</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>464</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>44</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   3    5    24   25   32   35   36   37   38\n",
       "Actual                                                \n",
       "3          722    3    0    1    1    0    1    2    0\n",
       "5            3  588    3    1    2    8   28   11    9\n",
       "24          11   17  362   11    2   12   33   18   19\n",
       "25           2   14    7  636    7   20   34   21   24\n",
       "32           3    3    7    9  309   18   18    4   17\n",
       "35           1    6    3    2    2  326    5   15   33\n",
       "36           4   41    8   11    3    9  520   11   13\n",
       "37           0    9    2    1    2   16    7  464   56\n",
       "38           2    9    2    0    3   48   14   44  494"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = y_test,\n",
    "            columns = knn_predictions,\n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.97      0.99      0.98       730\n",
      "           5       0.85      0.90      0.88       653\n",
      "          24       0.92      0.75      0.82       485\n",
      "          25       0.95      0.83      0.89       765\n",
      "          32       0.93      0.80      0.86       388\n",
      "          35       0.71      0.83      0.77       393\n",
      "          36       0.79      0.84      0.81       620\n",
      "          37       0.79      0.83      0.81       557\n",
      "          38       0.74      0.80      0.77       616\n",
      "\n",
      "    accuracy                           0.85      5207\n",
      "   macro avg       0.85      0.84      0.84      5207\n",
      "weighted avg       0.86      0.85      0.85      5207\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_predictions), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
